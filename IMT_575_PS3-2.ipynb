{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMT 575 PS3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mU2kXkkASqxS",
        "uPAP7XDlSYLP",
        "0cVWvCaZSuEz",
        "rXRN1AJPSvyB",
        "capvuMZdSwSr",
        "vUBWdlwASxuv",
        "zICazkraSy9J",
        "iLOKl1PoS240"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teVBSxxu2-b4",
        "colab_type": "text"
      },
      "source": [
        "# **Which US Democratic Presidential Nominee said this? Warren? Biden? Sanders?**\n",
        "---\n",
        "### *Text Classification of quotes from candidates vying to be the Democratic presidential nominee for the 2020 US presidential election.*\n",
        "---\n",
        "\n",
        "Here, all data has been extracted from debates between candidates. We will build a NLP classification model to identify who said what for a subset of unlabeled data.\n",
        "\n",
        "\n",
        "The quotes are subjected to basic text-preprocessing steps such as\n",
        "1. Stopword removal\n",
        "2. Punctuation removal\n",
        "3. Lemmatization\n",
        "4. Tokenization using unigram\n",
        "\n",
        "To prepare data for modeling, I performed feature engineering. Here, I engineered features which utilize count of various components of the text such as character, word, punctuation etc. \n",
        "\n",
        "The text classification is done using **Supervised & Semi-Supervised techniques.**\n",
        "\n",
        "The following models were explored:\n",
        "1. Regularized Logistic Regression\n",
        "2. Random Forest\n",
        "3. XGBoost\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kogtj7VFSBxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ecaccee5-607e-4921-bbb9-a8100432f494"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from scipy.sparse import hstack\n",
        "import string\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import xgboost as xgb\n",
        "import sklearn\n",
        "from sklearn import model_selection, preprocessing\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import WhitespaceTokenizer \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s3Zy00vuWJj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "3e2f6231-b4a6-418a-cb38-a3842beab1c4"
      },
      "source": [
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9xLCewwSM_J",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# Set up\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU2kXkkASqxS",
        "colab_type": "text"
      },
      "source": [
        "#### 1. Load training and test dataset into dataframe\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzPYfT0A6c1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_path = 'drive/My Drive/Colab Notebooks/Data/'\n",
        "def read_files(path):\n",
        "  onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
        "  name_list, file_list = [], []\n",
        "  print(\"Reading in \", len(onlyfiles), \" files.\")\n",
        "  for f in onlyfiles:\n",
        "    file = open(path + \"/\" + f, 'r')\n",
        "    lines  = file.readlines()\n",
        "    file_list.append(lines)\n",
        "    name_list.append(f.split(\"_\")[:2])\n",
        "  print(\"Read \", len(name_list), \" files.\")\n",
        "  return(name_list,file_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjTZaKb0x658",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9f752d18-2ad7-4551-fae1-9bdb557fc997"
      },
      "source": [
        "#reading train data\n",
        "train_path = base_path + \"train\"\n",
        "names, file_content = read_files(train_path) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading in  528  files.\n",
            "Read  528  files.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKLCWnr80Uok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert to dataframe\n",
        "#convert to data frame\n",
        "train_all = pd.DataFrame(file_content, columns = ['c'])\n",
        "split_data = train_all[\"c\"].str.split(\":\")\n",
        "#extract all names\n",
        "c_name = []\n",
        "c_quote = []\n",
        "for s in split_data:\n",
        "  c_name.append(s[0].split()[1].upper().replace(\"'\", \"\"))\n",
        "  c_quote.append(str(s[1:]))\n",
        "\n",
        "train_df = pd.DataFrame({\"label\" : c_name, \"Quotes\": c_quote})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc4mWBEA0g8v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b60096b9-ab19-4697-d315-e4f800a589ec"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Quotes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HARRIS</td>\n",
              "      <td>[' He was born… He has conducted foreign polic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OROURKE</td>\n",
              "      <td>[' How else can we explain that we lose nearly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HARRIS</td>\n",
              "      <td>[' Five million assault weapons are on the str...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BUTTIGIEG</td>\n",
              "      <td>[' My response is, I completely agree, and I w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SANDERS</td>\n",
              "      <td>[' Second of all… Maybe you did that and made ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       label                                             Quotes\n",
              "0     HARRIS  [' He was born… He has conducted foreign polic...\n",
              "1    OROURKE  [' How else can we explain that we lose nearly...\n",
              "2     HARRIS  [' Five million assault weapons are on the str...\n",
              "3  BUTTIGIEG  [' My response is, I completely agree, and I w...\n",
              "4    SANDERS  [' Second of all… Maybe you did that and made ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS61MmTtzGsG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17797dc1-53bd-4c0b-a52b-82c6f4429b71"
      },
      "source": [
        "#reading test data\n",
        "test_path = base_path + \"test\"\n",
        "test_file, test_list = read_files(test_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading in  111  files.\n",
            "Read  111  files.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23R-zLwFA0YH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_file = []\n",
        "for f_ in test_file:\n",
        "  new_file.append(\"_\".join(f_))\n",
        "#test_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QpJWzrzzfIA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "outputId": "47fb8029-485e-4b9c-d0c9-e60c8d1324cf"
      },
      "source": [
        "test_df = pd.DataFrame({\"file_name\" : new_file,\"Quotes\": test_list})\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>Quotes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_78.txt</td>\n",
              "      <td>[Yeah, I think that we’re on the right track i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_64.txt</td>\n",
              "      <td>[There are only two countries in the world tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_96.txt</td>\n",
              "      <td>[Sure, there’s one point we’re really missing ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_94.txt</td>\n",
              "      <td>[I’m not wedded to a particular solution, but ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_3.txt</td>\n",
              "      <td>[There’s a larger battle going on on the plane...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     file_name                                             Quotes\n",
              "0  test_78.txt  [Yeah, I think that we’re on the right track i...\n",
              "1  test_64.txt  [There are only two countries in the world tha...\n",
              "2  test_96.txt  [Sure, there’s one point we’re really missing ...\n",
              "3  test_94.txt  [I’m not wedded to a particular solution, but ...\n",
              "4   test_3.txt  [There’s a larger battle going on on the plane..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8w0oMvnPqNU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b484d461-8ab5-42b8-976e-9e8776dd976f"
      },
      "source": [
        "test_df['Quotes'] = test_df['Quotes'].apply(lambda x: ','.join(map(str, x)))\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>Quotes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_78.txt</td>\n",
              "      <td>Yeah, I think that we’re on the right track in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_64.txt</td>\n",
              "      <td>There are only two countries in the world that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_96.txt</td>\n",
              "      <td>Sure, there’s one point we’re really missing o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_94.txt</td>\n",
              "      <td>I’m not wedded to a particular solution, but I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_3.txt</td>\n",
              "      <td>There’s a larger battle going on on the planet...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     file_name                                             Quotes\n",
              "0  test_78.txt  Yeah, I think that we’re on the right track in...\n",
              "1  test_64.txt  There are only two countries in the world that...\n",
              "2  test_96.txt  Sure, there’s one point we’re really missing o...\n",
              "3  test_94.txt  I’m not wedded to a particular solution, but I...\n",
              "4   test_3.txt  There’s a larger battle going on on the planet..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsZU0O2wKk0K",
        "colab_type": "text"
      },
      "source": [
        "There are 528 training observations and 111 test observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPAP7XDlSYLP",
        "colab_type": "text"
      },
      "source": [
        "#### 2. Create a vector of training labels.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeFF4VrxK78v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5af7ad68-5276-44ca-9348-b83b36698563"
      },
      "source": [
        "#instances where the name of the file does not align with the name at the start of the text\n",
        "count = 0\n",
        "candidate_name = train_df.label\n",
        "for i in range(len(names)):\n",
        "  c = candidate_name[i].lower().strip()\n",
        "  #print(names[i], c)\n",
        "  if (names[i][0].lower().replace(\"'\", \"\") != c):\n",
        "    print(names[i][0], c)\n",
        "    count += 1\n",
        "print(\"There are\", count, \"mismatch in training files\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 0 mismatch in training files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GryEsLl2LEJh",
        "colab_type": "text"
      },
      "source": [
        "There are no observations where the candidate name in the file name and in the file content don't match.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6UAcU7KOJ-f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baf2dd86-0389-4732-e1f4-b366373faa53"
      },
      "source": [
        "#find training labels\n",
        "ax = sns.countplot(x='label',data=train_df)\n",
        "\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvfuieuLtHOC",
        "colab_type": "text"
      },
      "source": [
        "We can see that distribution is around ~60 for 5 candidates and for the other 5 it is around ~30 counts. The lowest count is for Tulsi Gabbard and highest for Elizabeth Warren."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3IZFavMOzUP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6cb8b6d-efb6-421d-fe05-d5720ee0a3f7"
      },
      "source": [
        "class_names = train_df.label.unique()\n",
        "print(\"There are\", len(class_names), \"candidates.\\nThey are as follows:\", class_names)\n",
        "#creating a vector of labels\n",
        "# label encode the target variable \n",
        "train_y = train_df.label\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y_vector = encoder.fit_transform(train_y)\n",
        "print(train_y_vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 12 candidates.\n",
            "They are as follows: ['HARRIS' 'OROURKE' 'BUTTIGIEG' 'SANDERS' 'BIDEN' 'WARREN' 'BOOKER' 'YANG'\n",
            " 'KLOBUCHAR' 'CASTRO' 'GABBARD' 'STEYER']\n",
            "[ 5  7  5  2  8  7  2  8  5  0 10  0  5 10  1  8 10  7  8  2  0 11  0  6\n",
            " 10  6 10  7  5  0 10 11  8  5  1  7 10  6  8 11 10  7  1 10 10  0  5  2\n",
            "  6  0 11  2 10  6  6  2  5  5  7  1 10  7  6  7  2 10  5  2 10 10  6  5\n",
            "  6 10 11  5  8  2  8  8 10  6 10 10 10  8  2 10  8  3  1  0 10  7 11  6\n",
            "  1  0  1 11  6  8  0  7 10  5  8  5  5  2  0 11  1  1 10  1  5  3  8  7\n",
            "  7  8  3  6 10  1  2  3 10  5  7  1  2 10  6  1  0  6  5 10 10 10  1  6\n",
            "  1  3 10 10  8  2  2  2 10  1  7  8  6  5 10 11  2  6  7 11  0  3  1 11\n",
            "  5  5  7  8 10  2 10  8  0 10  0  6  8  8 10 11  5  8  0 11  0  8  7  5\n",
            "  2  1  0  8  3  6  1  5 10  1  0 10 10 11  8  1  8  2  6  7  6 10  1 10\n",
            " 11  0 11  0  7  8  8  3  8  0  8  5  6 10  6  6 10  3  7  0  8  0  7  8\n",
            "  6 10  6  5  3  6  6  1  0  8  8  1  8  6  3  6  8  6  2 11  6  2 10 11\n",
            "  5 10  5  3  2 10  7  7 10  6  5 10  6  1  8 11  5 11  1 10  6 10  7  2\n",
            "  0  7 10  7  0  8  1  7 10 11  5 10  8  3  2 10  8  2  8  5  8 10  0  2\n",
            "  3 10  2  3  7  5  2 10 10  5 10  7 10  6 10  3  1 10  0 10  2  1 10 10\n",
            " 10  2  2  1  0  5 10  2  6  6  2  3  8  3 10 11  2  1 10  1  1 10 10  1\n",
            "  5  0  8  8  0  2  1  1  2 10  8 11 10  0  0  0  0  6  8  6  2  8  1 10\n",
            "  5  5  2  1  6  2  2  1 11  1  0  2  6  2 11  1  7 11  0  1  6  6  7  4\n",
            "  9  4  9  0  0  0  4  9  9  0  0  4  0  4  9  4  9  9  4  4  4  0  4  9\n",
            "  0  9  9  0  9  4  9  4  0  4  9  0  4  9  0  9  4  4  0  9  0  0  0  9\n",
            "  9  0  0  9  6 11  2  2 11  2  5  5  6  3  6  6  3  8  8  1  2  0  0  6\n",
            "  1  1  8  1  1  2  2 11  1  1  8  3  0  1  6  6  2  6  2  6  8  2 10  7\n",
            "  8  8  8  2  2  3  0  8  2 11  8  8  3 11  2 11  2  6 10  2 10  8  2  2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cVWvCaZSuEz",
        "colab_type": "text"
      },
      "source": [
        "#### 3. Remove stopwords & punctuations\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kefrd29Txk5N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9701ac28-b9f3-4cb3-f257-d4e0e7d7cfeb"
      },
      "source": [
        "#to find custom stopwords\n",
        "count_words = train_df.Quotes.str.split(expand=True).stack().value_counts(normalize=True).mul(100).round(3)\n",
        "for ix, c in count_words[:50].items():\n",
        "  print(ix, c)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the 4.265\n",
            "to 3.491\n",
            "and 2.513\n",
            "of 2.185\n",
            "that 2.178\n",
            "a 1.963\n",
            "I 1.913\n",
            "in 1.878\n",
            "we 1.592\n",
            "is 1.463\n",
            "have 1.113\n",
            "for 1.018\n",
            "this 0.958\n",
            "[' 0.807\n",
            "on 0.776\n",
            "And 0.698\n",
            "our 0.69\n",
            "it 0.684\n",
            "are 0.673\n",
            "not 0.643\n",
            "you 0.608\n",
            "people 0.595\n",
            "with 0.585\n",
            "what 0.56\n",
            "be 0.552\n",
            "about 0.511\n",
            "who 0.451\n",
            "do 0.451\n",
            "We 0.439\n",
            "they 0.424\n",
            "was 0.416\n",
            "will 0.415\n",
            "going 0.384\n",
            "as 0.375\n",
            "my 0.361\n",
            "has 0.358\n",
            "all 0.32\n",
            "get 0.32\n",
            "but 0.318\n",
            "at 0.318\n",
            "can 0.309\n",
            "when 0.305\n",
            "from 0.297\n",
            "think 0.289\n",
            "because 0.286\n",
            "their 0.283\n",
            "need 0.283\n",
            "up 0.28\n",
            "by 0.279\n",
            "he 0.271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzBlc1V00XX8",
        "colab_type": "text"
      },
      "source": [
        "Here after finding the frequency of the words in the quotes, we notice that amongst the general stopwords of english languages other words such as - United, States, America, American, People appear too. It is obvious that candidates vying for the ticker will be using these words in their speeches and hence can be added to the stopwords list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYc3CbfataEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_stopwords = nltk.corpus.stopwords.words('english')\n",
        "my_stopwords.extend([\"america\", \"american\", \"united\", \"people\"])\n",
        "my_punctuation = '!\"$%&\\'()*+,-.…/:;<=>?[\\\\]^_`{|}~•@’'\n",
        "def cleanQuotes(quote):\n",
        "  #print(quote)\n",
        "  quote = quote.lower() # lower case\n",
        "  #print(quote)\n",
        "  quote = quote.strip()#remove double spacing\n",
        "  #quote_new = quote.translate(str.maketrans(dict.fromkeys(string.punctuation)))  \n",
        "  quote = \"\".join([char.lower() for char in quote if char not in my_punctuation]) \n",
        "  quote = re.sub('['+my_punctuation + ']+', ' ', quote) # strip punctuation\n",
        "  quote = \" \".join([word for word in quote.split(' ') if word not in my_stopwords])\n",
        "  return quote.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNz0aTWE0rv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['clean_quote'] = train_df.Quotes.apply(cleanQuotes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXKByQqq1G14",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "973eb6eb-6e2a-4c9d-8825-b0af90f209c5"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Quotes</th>\n",
              "      <th>clean_quote</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HARRIS</td>\n",
              "      <td>[' He was born… He has conducted foreign polic...</td>\n",
              "      <td>born conducted foreign policy since day one bo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OROURKE</td>\n",
              "      <td>[' How else can we explain that we lose nearly...</td>\n",
              "      <td>else explain lose nearly 40000 country gun vio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HARRIS</td>\n",
              "      <td>[' Five million assault weapons are on the str...</td>\n",
              "      <td>five million assault weapons streets today cou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BUTTIGIEG</td>\n",
              "      <td>[' My response is, I completely agree, and I w...</td>\n",
              "      <td>response completely agree welcome challenge co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SANDERS</td>\n",
              "      <td>[' Second of all… Maybe you did that and made ...</td>\n",
              "      <td>second maybe made money healthcare job run non...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  ...                                        clean_quote\n",
              "0     HARRIS  ...  born conducted foreign policy since day one bo...\n",
              "1    OROURKE  ...  else explain lose nearly 40000 country gun vio...\n",
              "2     HARRIS  ...  five million assault weapons streets today cou...\n",
              "3  BUTTIGIEG  ...  response completely agree welcome challenge co...\n",
              "4    SANDERS  ...  second maybe made money healthcare job run non...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc6YJxA4StfR",
        "colab_type": "text"
      },
      "source": [
        "#### 4. Stem/lemmatize your training data using a stemmer/lemmatizer of your choosing\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEcy-r5V2WZq",
        "colab_type": "text"
      },
      "source": [
        "Stem/lemmatize your training data using a stemmer/lemmatizer of your choosing. Show a before and after using a few observations and comment on what you see."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QejnzxBa2TMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmatizer = WordNetLemmatizer() \n",
        "tk = WhitespaceTokenizer() \n",
        "def lemmatizeQuotes(quote):\n",
        "  quote = \" \".join([lemmatizer.lemmatize(word) for word in tk.tokenize(quote)])\n",
        "  return(quote)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZA55A-I8HS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df[\"final_clean\"] = train_df.clean_quote.apply(lambda x: lemmatizeQuotes(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opLjhMk68Smt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "cd5dcfa0-7fed-44e0-93bf-03132ba1c928"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Quotes</th>\n",
              "      <th>clean_quote</th>\n",
              "      <th>final_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HARRIS</td>\n",
              "      <td>[' He was born… He has conducted foreign polic...</td>\n",
              "      <td>born conducted foreign policy since day one bo...</td>\n",
              "      <td>born conducted foreign policy since day one bo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OROURKE</td>\n",
              "      <td>[' How else can we explain that we lose nearly...</td>\n",
              "      <td>else explain lose nearly 40000 country gun vio...</td>\n",
              "      <td>else explain lose nearly 40000 country gun vio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HARRIS</td>\n",
              "      <td>[' Five million assault weapons are on the str...</td>\n",
              "      <td>five million assault weapons streets today cou...</td>\n",
              "      <td>five million assault weapon street today cours...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BUTTIGIEG</td>\n",
              "      <td>[' My response is, I completely agree, and I w...</td>\n",
              "      <td>response completely agree welcome challenge co...</td>\n",
              "      <td>response completely agree welcome challenge co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SANDERS</td>\n",
              "      <td>[' Second of all… Maybe you did that and made ...</td>\n",
              "      <td>second maybe made money healthcare job run non...</td>\n",
              "      <td>second maybe made money healthcare job run non...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  ...                                        final_clean\n",
              "0     HARRIS  ...  born conducted foreign policy since day one bo...\n",
              "1    OROURKE  ...  else explain lose nearly 40000 country gun vio...\n",
              "2     HARRIS  ...  five million assault weapon street today cours...\n",
              "3  BUTTIGIEG  ...  response completely agree welcome challenge co...\n",
              "4    SANDERS  ...  second maybe made money healthcare job run non...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQw5hHkZHoYw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1c76095-6ba7-4291-a61b-10773db1cbdf"
      },
      "source": [
        "for i in range(3):\n",
        "  print(\"The text\\n\",train_df.iloc[i, 2])\n",
        "  print(\"After lemmatization\\n\",train_df.iloc[i, 3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The text\n",
            " born conducted foreign policy since day one born fragile ego fails understand one important responsibilities commanderinchief concern security nation homeland way understands part strength nation therefore extension ability secure vibrant military walk room around globe respected keep word consistent speak truth loyal donald trump done pulling paris agreement pulling iran nuclear deal consistently turning back stood us difficult times including recently kurds points donald trump greatest threat national security nation moment\n",
            "After lemmatization\n",
            " born conducted foreign policy since day one born fragile ego fails understand one important responsibility commanderinchief concern security nation homeland way understands part strength nation therefore extension ability secure vibrant military walk room around globe respected keep word consistent speak truth loyal donald trump done pulling paris agreement pulling iran nuclear deal consistently turning back stood u difficult time including recently kurd point donald trump greatest threat national security nation moment\n",
            "The text\n",
            " else explain lose nearly 40000 country gun violence number country comes even close know solutions yet nothing changed country money buys influence access increasingly outcomes centers disease control prevented actually studying issue first place president make sure ban political action committee contributions member congress candidate federal office listen panderson coopers corporations special interests\n",
            "After lemmatization\n",
            " else explain lose nearly 40000 country gun violence number country come even close know solution yet nothing changed country money buy influence access increasingly outcome center disease control prevented actually studying issue first place president make sure ban political action committee contribution member congress candidate federal office listen panderson cooper corporation special interest\n",
            "The text\n",
            " five million assault weapons streets today course debate eight die gun violence leading cause death young black men gun violence top six reasons totaled serious matter personally hugged mothers homicide victims care tell looked autopsy photographs care tell attended police officer funerals care tell im done need action congress years act failed courage im elected ill give 100 days pull act together put bill desk signature dont take executive action put place comprehensive background check requirement ban importation assault weapons country cause time act\n",
            "After lemmatization\n",
            " five million assault weapon street today course debate eight die gun violence leading cause death young black men gun violence top six reason totaled serious matter personally hugged mother homicide victim care tell looked autopsy photograph care tell attended police officer funeral care tell im done need action congress year act failed courage im elected ill give 100 day pull act together put bill desk signature dont take executive action put place comprehensive background check requirement ban importation assault weapon country cause time act\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj3TZD38KTbv",
        "colab_type": "text"
      },
      "source": [
        "As is observed from the texts, plurals such as mothers, victims are converted to mother, victim. I chose lemmatization as it generates valid lemma."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXRN1AJPSvyB",
        "colab_type": "text"
      },
      "source": [
        "#### 5. Tokenize your training data using unigrams\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikPM-Wnu2kBm",
        "colab_type": "text"
      },
      "source": [
        "Tokenize your training data using unigrams (hint: see sklearn’s CountVectorizer). If you set upper and lower limits on word frequency, what are they? How many unique tokens are in your vocabulary?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-KllLtz20GG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc218cec-5349-4666-eb33-3889d15b3fff"
      },
      "source": [
        "vectorizer = CountVectorizer(max_df=0.95, min_df=13, ngram_range=(1, 1))\n",
        "# apply transformation\n",
        "train_x = vectorizer.fit_transform(train_df['final_clean'])\n",
        "tf_feature_names = vectorizer.get_feature_names()\n",
        "print(\"There are \", len(tf_feature_names), \"unique tokens in our vocabulary\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are  432 unique tokens in our vocabulary\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l3mvZTxOC-y",
        "colab_type": "text"
      },
      "source": [
        "Here, I have used a max_df of 0.95 to ignore words which occur in more than 95% of documents and min_df 13 to eliminate those which occur in less than 13 documents as there were no candidates with less than 13 quotes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "capvuMZdSwSr",
        "colab_type": "text"
      },
      "source": [
        "#### 6. Process the test data in a manner identical to the training data.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv_Y1MHeO0cv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_x = vectorizer.transform(test_df.Quotes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jffJfsYoQEDP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86a0531c-6aae-41c9-f292-a970da5f8da5"
      },
      "source": [
        "print(\"The number of feature in training is\", train_x.shape[1], \"and in test is\" ,test_x.shape[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of feature in training is 432 and in test is 432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS2SAXhtQzle",
        "colab_type": "text"
      },
      "source": [
        "Therefore, the number of features for your training and test data are identical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eO8XY2hSSFT",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# Supervised Learning\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEDyFpNdSxQp",
        "colab_type": "text"
      },
      "source": [
        "#### 7. Feature Engineering\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJQxvEB9Q79N",
        "colab_type": "text"
      },
      "source": [
        "Here, I engineered features which utilize count of various components of the text such as character, word, punctuation etc. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fp0Hku2TdeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['char_count'] = train_df['Quotes'].apply(len)\n",
        "train_df['word_count'] = train_df['Quotes'].apply(lambda x: len(x.split()))\n",
        "train_df['word_density'] = train_df['char_count']/(train_df['word_count'] + 1)\n",
        "train_df['punctuation_count'] = train_df['Quotes'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
        "train_df['title_word_count'] = train_df['Quotes'].apply(lambda x: len([word for word in x.split() if word.istitle()]))\n",
        "train_df['upper_case_word_count'] = train_df['Quotes'].apply(lambda x: len([word for word in x.split() if word.isupper()]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFw01QeYlRHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['char_count'] = test_df['Quotes'].apply(len)\n",
        "test_df['word_count'] = test_df['Quotes'].apply(lambda x: len(x.split()))\n",
        "test_df['word_density'] = test_df['char_count']/(test_df['word_count']+1)\n",
        "test_df['punctuation_count'] = test_df['Quotes'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
        "test_df['title_word_count'] = test_df['Quotes'].apply(lambda x: len([word for word in x.split() if word.istitle()]))\n",
        "test_df['upper_case_word_count'] = test_df['Quotes'].apply(lambda x: len([word for word in x.split() if word.isupper()]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAJoq8sejlBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_features = [f_ for f_ in train_df.columns\\\n",
        "                if f_ in [\"char_count\", \"word_count\", \"word_density\", 'punctuation_count','title_word_count', 'upper_case_word_count']]\n",
        "\n",
        "for f in num_features:\n",
        "    all_cut = pd.cut(pd.concat([train_df[f], test_df[f]], axis=0), bins=20, labels=False, retbins=False)\n",
        "    train_df[f] = all_cut.values[:train_df.shape[0]]\n",
        "    test_df[f] = all_cut.values[train_df.shape[0]:]\n",
        "\n",
        "train_num_features = train_df[num_features].values\n",
        "test_num_features = test_df[num_features].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j_D3ifFlqdu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = hstack([train_x, train_num_features]) \n",
        "test_features = hstack([test_x, test_num_features])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYeOVKzBmgIH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a7c1fc-6615-4cfa-ce1a-0e6d87963e6e"
      },
      "source": [
        "print(\"The number of features in train set\", train_features.shape[1])\n",
        "print(\"The number of features in test set\", test_features.shape[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of features in train set 438\n",
            "The number of features in test set 438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnH7_YtUztG7",
        "colab_type": "text"
      },
      "source": [
        "Thus, the number of features remain identical after adding 6 more features. These features were added to the countVectorizer generated features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUBWdlwASxuv",
        "colab_type": "text"
      },
      "source": [
        "#### 8. Regularized Logistic Regression Model\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfC3ch5h3mI8",
        "colab_type": "text"
      },
      "source": [
        "Here I have used L1 regulaization for the losgistic regression model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U62KHwEpnYX2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1256a243-0624-4ae2-bb3e-643dd022050d"
      },
      "source": [
        "clf_rl = LogisticRegression(penalty=\"l1\", solver='liblinear')\n",
        "clf_rl.fit(train_features,train_y)\n",
        "print(\"For the regularized logistic regression, the coefficents are as follows:\\n\")\n",
        "print(clf_rl.coef_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For the regularized logistic regression, the coefficents are as follows:\n",
            "\n",
            "[[ 0.          0.          0.         ...  0.31791381  0.16142344\n",
            "  -0.09281191]\n",
            " [ 0.          0.          0.         ... -0.14105083 -0.05026256\n",
            "  -0.12746043]\n",
            " [ 0.          0.          0.452483   ... -0.41088216 -0.13892871\n",
            "  -0.03996163]\n",
            " ...\n",
            " [ 0.          0.          0.         ... -0.43695904  0.\n",
            "  -0.19559368]\n",
            " [ 0.          0.          0.         ...  0.         -0.10927211\n",
            "   0.06460022]\n",
            " [ 0.          0.          0.         ... -0.04604217 -0.02667437\n",
            "  -0.14576445]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zJWigjyp6DI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a46eaef6-3a9d-45a4-82f8-84c67aba88bf"
      },
      "source": [
        "print(\"The training accuracy score is\", clf_rl.score(train_features, train_y)*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training accuracy score is 96.96969696969697 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ke-cBj_y536Q",
        "colab_type": "text"
      },
      "source": [
        "The model performs exceptionally well in terms of accuracy. Now, lets explore class-specific metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPFo-H6t0hX2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87966475-4236-43d0-8683-ed486b974924"
      },
      "source": [
        "rl_report = classification_report(train_y, clf_rl.predict(train_features))\n",
        "\n",
        "matrix = confusion_matrix(train_y, clf_rl.predict(train_features), labels = class_names)\n",
        "rl_acc = matrix.diagonal()/matrix.sum(axis=1 )\n",
        "c1_df = pd.DataFrame({'accuracy': rl_acc}, index=class_names)\n",
        "cm1_df = pd.DataFrame(matrix, index = class_names, columns = class_names)\n",
        "\n",
        "print(rl_report)\n",
        "print(\"=========================================================\\n\\n\\nThe accuracy for each class is\\n\\n\\n\", c1_df)\n",
        "print(\"=========================================================\\n\\n\\nConfusion Matrix\\n\\n\")\n",
        "cm1_df.head(12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       BIDEN       0.97      0.97      0.97        60\n",
            "      BOOKER       0.98      0.94      0.96        50\n",
            "   BUTTIGIEG       0.95      1.00      0.98        60\n",
            "      CASTRO       0.95      0.91      0.93        23\n",
            "     GABBARD       1.00      1.00      1.00        16\n",
            "      HARRIS       0.97      0.97      0.97        40\n",
            "   KLOBUCHAR       1.00      0.98      0.99        55\n",
            "     OROURKE       1.00      1.00      1.00        33\n",
            "     SANDERS       0.98      1.00      0.99        60\n",
            "      STEYER       1.00      1.00      1.00        19\n",
            "      WARREN       0.92      0.97      0.95        80\n",
            "        YANG       1.00      0.84      0.92        32\n",
            "\n",
            "    accuracy                           0.97       528\n",
            "   macro avg       0.98      0.97      0.97       528\n",
            "weighted avg       0.97      0.97      0.97       528\n",
            "\n",
            "=========================================================\n",
            "\n",
            "\n",
            "The accuracy for each class is\n",
            "\n",
            "\n",
            "            accuracy\n",
            "HARRIS     0.975000\n",
            "OROURKE    1.000000\n",
            "BUTTIGIEG  1.000000\n",
            "SANDERS    1.000000\n",
            "BIDEN      0.966667\n",
            "WARREN     0.975000\n",
            "BOOKER     0.940000\n",
            "YANG       0.843750\n",
            "KLOBUCHAR  0.981818\n",
            "CASTRO     0.913043\n",
            "GABBARD    1.000000\n",
            "STEYER     1.000000\n",
            "=========================================================\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HARRIS</th>\n",
              "      <th>OROURKE</th>\n",
              "      <th>BUTTIGIEG</th>\n",
              "      <th>SANDERS</th>\n",
              "      <th>BIDEN</th>\n",
              "      <th>WARREN</th>\n",
              "      <th>BOOKER</th>\n",
              "      <th>YANG</th>\n",
              "      <th>KLOBUCHAR</th>\n",
              "      <th>CASTRO</th>\n",
              "      <th>GABBARD</th>\n",
              "      <th>STEYER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>HARRIS</th>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OROURKE</th>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BUTTIGIEG</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SANDERS</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BIDEN</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WARREN</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BOOKER</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>YANG</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KLOBUCHAR</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CASTRO</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GABBARD</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STEYER</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           HARRIS  OROURKE  BUTTIGIEG  ...  CASTRO  GABBARD  STEYER\n",
              "HARRIS         39        0          1  ...       0        0       0\n",
              "OROURKE         0       33          0  ...       0        0       0\n",
              "BUTTIGIEG       0        0         60  ...       0        0       0\n",
              "SANDERS         0        0          0  ...       0        0       0\n",
              "BIDEN           0        0          0  ...       0        0       0\n",
              "WARREN          0        0          0  ...       1        0       0\n",
              "BOOKER          1        0          0  ...       0        0       0\n",
              "YANG            0        0          1  ...       0        0       0\n",
              "KLOBUCHAR       0        0          0  ...       0        0       0\n",
              "CASTRO          0        0          1  ...      21        0       0\n",
              "GABBARD         0        0          0  ...       0       16       0\n",
              "STEYER          0        0          0  ...       0        0      19\n",
              "\n",
              "[12 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNywuKv-6D31",
        "colab_type": "text"
      },
      "source": [
        "As is made obvious from the confusion metrics, there are very few misclassified data points. From observing the accuracy and confusion matrix, we know that the candidate - YANG has the most misclassified quotes with a count of 5 and accuracy of 0.843. Thus, here the performance of the model is not as good as other classes where there are no to 2 misclassified points. It is also worth noting that the classifier has 100% accuracy for classes GABBARD, SANDER, BUTTIGIEG, OROURKE, STEYER alongwith almost perfect precision, recall and f1- score in some of these classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zICazkraSy9J",
        "colab_type": "text"
      },
      "source": [
        "#### 9. Tree-based Model\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idaVsBdv7sRa",
        "colab_type": "text"
      },
      "source": [
        "Here, I'm using a random forest model as there ensemble component will help idenitfy good split criteria. It also decorrelates tree though at the expense of interpretability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEi57FhjrJiG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e5353a-fdd6-4d49-81b3-d4656e283b87"
      },
      "source": [
        "clf_rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        "            max_depth=100, max_leaf_nodes=None, min_impurity_split=None,\n",
        "            min_samples_leaf=3, min_samples_split=10, n_estimators=10, random_state=None)\n",
        "\n",
        "clf_rf.fit(train_features,train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=100, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=3, min_samples_split=10,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqkUV5X2rfT9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0056ec71-91e4-41a4-ff10-6f7d599bee17"
      },
      "source": [
        "print(\"The training accuracy score is\", clf_rf.score(train_features, train_y)*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training accuracy score is 81.25 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu6C2Snp8xC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "139fe2e2-94ee-4fc2-f235-521160e31dc5"
      },
      "source": [
        "rf_report = classification_report(train_y, clf_rf.predict(train_features))\n",
        "\n",
        "matrix = confusion_matrix(train_y, clf_rf.predict(train_features), labels = class_names)\n",
        "rf_acc = matrix.diagonal()/matrix.sum(axis=1 )\n",
        "c2_df = pd.DataFrame({'accuracy': rf_acc}, index=class_names)\n",
        "cm2_df = pd.DataFrame(matrix, index = class_names, columns = class_names)\n",
        "\n",
        "print(rf_report)\n",
        "print(\"=========================================================\\n\\n\\nThe accuracy for each class is\\n\\n\\n\", c2_df)\n",
        "print(\"=========================================================\\n\\n\\nConfusion Matrix\\n\\n\")\n",
        "cm2_df.head(12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       BIDEN       0.82      0.85      0.84        60\n",
            "      BOOKER       0.77      0.80      0.78        50\n",
            "   BUTTIGIEG       0.84      0.87      0.85        60\n",
            "      CASTRO       1.00      0.65      0.79        23\n",
            "     GABBARD       1.00      0.62      0.77        16\n",
            "      HARRIS       0.87      0.82      0.85        40\n",
            "   KLOBUCHAR       0.81      0.78      0.80        55\n",
            "     OROURKE       1.00      0.70      0.82        33\n",
            "     SANDERS       0.81      0.97      0.88        60\n",
            "      STEYER       1.00      0.63      0.77        19\n",
            "      WARREN       0.68      0.93      0.78        80\n",
            "        YANG       0.90      0.56      0.69        32\n",
            "\n",
            "    accuracy                           0.81       528\n",
            "   macro avg       0.87      0.77      0.80       528\n",
            "weighted avg       0.83      0.81      0.81       528\n",
            "\n",
            "=========================================================\n",
            "\n",
            "\n",
            "The accuracy for each class is\n",
            "\n",
            "\n",
            "            accuracy\n",
            "HARRIS     0.825000\n",
            "OROURKE    0.696970\n",
            "BUTTIGIEG  0.866667\n",
            "SANDERS    0.966667\n",
            "BIDEN      0.850000\n",
            "WARREN     0.925000\n",
            "BOOKER     0.800000\n",
            "YANG       0.562500\n",
            "KLOBUCHAR  0.781818\n",
            "CASTRO     0.652174\n",
            "GABBARD    0.625000\n",
            "STEYER     0.631579\n",
            "=========================================================\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HARRIS</th>\n",
              "      <th>OROURKE</th>\n",
              "      <th>BUTTIGIEG</th>\n",
              "      <th>SANDERS</th>\n",
              "      <th>BIDEN</th>\n",
              "      <th>WARREN</th>\n",
              "      <th>BOOKER</th>\n",
              "      <th>YANG</th>\n",
              "      <th>KLOBUCHAR</th>\n",
              "      <th>CASTRO</th>\n",
              "      <th>GABBARD</th>\n",
              "      <th>STEYER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>HARRIS</th>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OROURKE</th>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BUTTIGIEG</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SANDERS</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BIDEN</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WARREN</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>74</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BOOKER</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>YANG</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KLOBUCHAR</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CASTRO</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GABBARD</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STEYER</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           HARRIS  OROURKE  BUTTIGIEG  ...  CASTRO  GABBARD  STEYER\n",
              "HARRIS         33        0          0  ...       0        0       0\n",
              "OROURKE         0       23          3  ...       0        0       0\n",
              "BUTTIGIEG       1        0         52  ...       0        0       0\n",
              "SANDERS         0        0          0  ...       0        0       0\n",
              "BIDEN           1        0          1  ...       0        0       0\n",
              "WARREN          0        0          0  ...       0        0       0\n",
              "BOOKER          0        0          2  ...       0        0       0\n",
              "YANG            1        0          1  ...       0        0       0\n",
              "KLOBUCHAR       1        0          2  ...       0        0       0\n",
              "CASTRO          0        0          1  ...      15        0       0\n",
              "GABBARD         1        0          0  ...       0       10       0\n",
              "STEYER          0        0          0  ...       0        0      12\n",
              "\n",
              "[12 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIkBbHo09N14",
        "colab_type": "text"
      },
      "source": [
        "As is made obvious from the confusion matrix, there are more misclassified data points than the previous model. From observing the accuracy and confusion matrix, we know that the candidate - YANG has the most misclassified quotes with accuracy of 0.375. Thus, here the performance of the model for this class is worse than the previous model. Even for other classes the accuracy is lower with highest accuracy for BIDEN, WARREN, SANDERS with good f1 scores too."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZha1-hdSzln",
        "colab_type": "text"
      },
      "source": [
        "#### 10. Pick your own model\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sqq6JHNREL6",
        "colab_type": "text"
      },
      "source": [
        "The model of my choice is Gradient Boosted Decision Tree which I have implemented using python's XGBoost library. I have read a lot about it and have seen it becoming a winner algo in several Kaggle competition. To tune the parameters I used a grid search to tune the depth, estimators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AuVZO2kuOWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m_xgb = xgb.XGBClassifier(objective='binary:logistic',booster = \"gbtree\", eval_metric='auc')\n",
        "clf_xgb = model_selection.GridSearchCV(m_xgb,{'max_depth': [4,6, 8],'n_estimators': [50,100,200]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBAB-SWnx6n5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "88058206-98ae-4a51-fe4a-377ea1b8eb66"
      },
      "source": [
        "clf_xgb.fit(train_features,train_y)\n",
        "print(\"The best score\", clf_xgb.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best score 0.38061096136567835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMBozhTgy-bN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "c6039d0f-4eba-4542-d5ad-62908f93e212"
      },
      "source": [
        "print(\"The training accuracy score is\", clf_xgb.score(train_features, train_y)*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training accuracy score is 100.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c-O1_7j_GeB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "37934320-f517-4289-829d-e7bf9f4b9a5d"
      },
      "source": [
        "xg_report = classification_report(train_y, clf_xgb.predict(train_features))\n",
        "\n",
        "matrix = confusion_matrix(train_y, clf_xgb.predict(train_features), labels = class_names)\n",
        "xg_acc = matrix.diagonal()/matrix.sum(axis=1 )\n",
        "c3_df = pd.DataFrame({'accuracy': xg_acc}, index=class_names)\n",
        "cm3_df = pd.DataFrame(matrix, index = class_names, columns = class_names)\n",
        "\n",
        "print(xg_report)\n",
        "print(\"=========================================================\\n\\n\\nThe accuracy for each class is\\n\\n\\n\", c3_df)\n",
        "print(\"=========================================================\\n\\n\\nConfusion Matrix\\n\\n\")\n",
        "cm3_df.head(12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       BIDEN       1.00      1.00      1.00        60\n",
            "      BOOKER       1.00      1.00      1.00        50\n",
            "   BUTTIGIEG       1.00      1.00      1.00        60\n",
            "      CASTRO       1.00      1.00      1.00        23\n",
            "     GABBARD       1.00      1.00      1.00        16\n",
            "      HARRIS       1.00      1.00      1.00        40\n",
            "   KLOBUCHAR       1.00      1.00      1.00        55\n",
            "     OROURKE       1.00      1.00      1.00        33\n",
            "     SANDERS       1.00      1.00      1.00        60\n",
            "      STEYER       1.00      1.00      1.00        19\n",
            "      WARREN       1.00      1.00      1.00        80\n",
            "        YANG       1.00      1.00      1.00        32\n",
            "\n",
            "    accuracy                           1.00       528\n",
            "   macro avg       1.00      1.00      1.00       528\n",
            "weighted avg       1.00      1.00      1.00       528\n",
            "\n",
            "=========================================================\n",
            "\n",
            "\n",
            "The accuracy for each class is\n",
            "\n",
            "\n",
            "            accuracy\n",
            "HARRIS          1.0\n",
            "OROURKE         1.0\n",
            "BUTTIGIEG       1.0\n",
            "SANDERS         1.0\n",
            "BIDEN           1.0\n",
            "WARREN          1.0\n",
            "BOOKER          1.0\n",
            "YANG            1.0\n",
            "KLOBUCHAR       1.0\n",
            "CASTRO          1.0\n",
            "GABBARD         1.0\n",
            "STEYER          1.0\n",
            "=========================================================\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HARRIS</th>\n",
              "      <th>OROURKE</th>\n",
              "      <th>BUTTIGIEG</th>\n",
              "      <th>SANDERS</th>\n",
              "      <th>BIDEN</th>\n",
              "      <th>WARREN</th>\n",
              "      <th>BOOKER</th>\n",
              "      <th>YANG</th>\n",
              "      <th>KLOBUCHAR</th>\n",
              "      <th>CASTRO</th>\n",
              "      <th>GABBARD</th>\n",
              "      <th>STEYER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>HARRIS</th>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OROURKE</th>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BUTTIGIEG</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SANDERS</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BIDEN</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WARREN</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BOOKER</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>YANG</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KLOBUCHAR</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CASTRO</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GABBARD</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STEYER</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           HARRIS  OROURKE  BUTTIGIEG  ...  CASTRO  GABBARD  STEYER\n",
              "HARRIS         40        0          0  ...       0        0       0\n",
              "OROURKE         0       33          0  ...       0        0       0\n",
              "BUTTIGIEG       0        0         60  ...       0        0       0\n",
              "SANDERS         0        0          0  ...       0        0       0\n",
              "BIDEN           0        0          0  ...       0        0       0\n",
              "WARREN          0        0          0  ...       0        0       0\n",
              "BOOKER          0        0          0  ...       0        0       0\n",
              "YANG            0        0          0  ...       0        0       0\n",
              "KLOBUCHAR       0        0          0  ...       0        0       0\n",
              "CASTRO          0        0          0  ...      23        0       0\n",
              "GABBARD         0        0          0  ...       0       16       0\n",
              "STEYER          0        0          0  ...       0        0      19\n",
              "\n",
              "[12 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCITmIeJ_MjG",
        "colab_type": "text"
      },
      "source": [
        "As is made obvious from the confusion matrix, there are no misclassified data points. This might be due to overfitting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ7bwHr9S0Ar",
        "colab_type": "text"
      },
      "source": [
        "#### 11. Compare the performance of the three classifiers you built\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qrIYkm1_UPG",
        "colab_type": "text"
      },
      "source": [
        "In my opinion, the best classifier in terms of accuracy, precision, and time is regularized logistic regression. While XGBoost has a perfect score on all evaluation metric, I'm worried it might be overfitting to the training data. In addition to this, it takes 2.5 - 3 mins to train. Thus, if I were to rank the performance only on the quantitative values while ignoring other potential issues, the ranking is - XGBoost, Reguliarized Logistic Regression, Random Forest.\n",
        "\n",
        "However, as mentioned before I'm a bit hesistant about the perfect score of XGBoost as this might be potentially due to overfitting resulting in poor performance on the test data. Additionally, it takes 2.5- 3 min to train as compared to a few seconds taken by the other two models. Thus, the best classifier ranked then is Regularized Logistic Regression, XGBoost, Random Forest. Random Forest gives poorer metric score and it is acceptable to spend more time on XGBoost to get better result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWiKVmTZA7Ir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "ad6bb687-287c-404d-fa59-fa0c05fa0adf"
      },
      "source": [
        "#create graph comparing accuracy and f1 score accross different class.\n",
        "x = class_names\n",
        "plt.plot(c3_df.index, c3_df.accuracy)\n",
        "plt.plot(c1_df.index, c1_df.accuracy)\n",
        "plt.plot(c2_df.index, c2_df.accuracy)\n",
        "\n",
        "plt.title(\"Class-wise Accuracy\")\n",
        "plt.legend(['XGBoost', 'Logistic', 'Random Forest'], loc='lower left')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P_DBlB1p8eH",
        "colab_type": "text"
      },
      "source": [
        "It is obvious from the graph that while logistic regression approaches the apparent state of the art / overfitted solution of XGBoost for some classes, it also performs significantly well in those classes where random forest has almost 50% accuracy. This shows that it is doing a good job at learning features and fitting to the training data while ignoring noises and thus, should retain this while dealing with unseen test dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk8U-XeuS0ja",
        "colab_type": "text"
      },
      "source": [
        "#### 12. Generate labels\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka6djlOfRJj-",
        "colab_type": "text"
      },
      "source": [
        "Here, I'm using the regularized logistic regression model to generate labels\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcSPvo_qBQWk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "026ae478-6a2d-4a04-e793-eed6f1cf8d8f"
      },
      "source": [
        "#generate labels\n",
        "part_2_labels = clf_rl.predict(test_features)\n",
        "print(part_2_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['BUTTIGIEG' 'YANG' 'STEYER' 'BUTTIGIEG' 'GABBARD' 'BUTTIGIEG' 'WARREN'\n",
            " 'SANDERS' 'GABBARD' 'BUTTIGIEG' 'BOOKER' 'BUTTIGIEG' 'GABBARD'\n",
            " 'BUTTIGIEG' 'KLOBUCHAR' 'WARREN' 'YANG' 'SANDERS' 'BUTTIGIEG' 'YANG'\n",
            " 'WARREN' 'BOOKER' 'BUTTIGIEG' 'BIDEN' 'HARRIS' 'SANDERS' 'OROURKE'\n",
            " 'HARRIS' 'YANG' 'GABBARD' 'HARRIS' 'STEYER' 'GABBARD' 'SANDERS' 'WARREN'\n",
            " 'BUTTIGIEG' 'WARREN' 'OROURKE' 'BOOKER' 'WARREN' 'WARREN' 'YANG'\n",
            " 'KLOBUCHAR' 'BUTTIGIEG' 'BOOKER' 'HARRIS' 'BIDEN' 'SANDERS' 'WARREN'\n",
            " 'KLOBUCHAR' 'BUTTIGIEG' 'YANG' 'KLOBUCHAR' 'BIDEN' 'KLOBUCHAR'\n",
            " 'KLOBUCHAR' 'KLOBUCHAR' 'SANDERS' 'WARREN' 'CASTRO' 'WARREN' 'KLOBUCHAR'\n",
            " 'BUTTIGIEG' 'OROURKE' 'WARREN' 'BUTTIGIEG' 'KLOBUCHAR' 'OROURKE'\n",
            " 'BUTTIGIEG' 'WARREN' 'HARRIS' 'OROURKE' 'BUTTIGIEG' 'BIDEN' 'SANDERS'\n",
            " 'BUTTIGIEG' 'WARREN' 'SANDERS' 'YANG' 'BOOKER' 'WARREN' 'BUTTIGIEG'\n",
            " 'SANDERS' 'BIDEN' 'SANDERS' 'STEYER' 'KLOBUCHAR' 'OROURKE' 'BOOKER'\n",
            " 'KLOBUCHAR' 'BUTTIGIEG' 'BIDEN' 'BIDEN' 'BOOKER' 'BUTTIGIEG' 'WARREN'\n",
            " 'YANG' 'WARREN' 'WARREN' 'BOOKER' 'OROURKE' 'WARREN' 'BUTTIGIEG'\n",
            " 'KLOBUCHAR' 'WARREN' 'GABBARD' 'YANG' 'SANDERS' 'CASTRO' 'BUTTIGIEG'\n",
            " 'WARREN']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzPfFAUaSU9z",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# Semi-Supervised Learning\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLOKl1PoS240",
        "colab_type": "text"
      },
      "source": [
        "#### 13. Pick Model\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFz6rQzXSg6u",
        "colab_type": "text"
      },
      "source": [
        "The model of my choice is the regularized logistic regression model as it performed exceptionally well in terms of accuracy, precision, recall, f1-score and time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPRkUy0sykul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf_semi = sklearn.base.clone(clf_rl, safe=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_KUPfHFS3SP",
        "colab_type": "text"
      },
      "source": [
        "#### 14. First iteration\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgMZqEN7M361",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "7fbef1b9-a77a-4fd6-e30b-66056b9c877f"
      },
      "source": [
        "#fit to un edited train data \n",
        "clf_semi.fit(train_features,train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKWaCpCqGazF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "27a60750-a2c1-49fa-c075-7810fa540013"
      },
      "source": [
        "print(\"The accuracy of the model before iteration on the original train data is\" ,clf_semi.score(train_features,train_y) * 100, \"%\" )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the model before iteration on the original train data is 96.96969696969697 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faJFMDqkipW5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "cdfca9f1-889d-44a5-fd36-268fd4db96ba"
      },
      "source": [
        "#create duplicates of train and test data frame to edit \n",
        "dup_train = train_df\n",
        "#dup_train.tail(20)\n",
        "dup_test = test_df    \n",
        "dup_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>Quotes</th>\n",
              "      <th>char_count</th>\n",
              "      <th>word_count</th>\n",
              "      <th>word_density</th>\n",
              "      <th>punctuation_count</th>\n",
              "      <th>title_word_count</th>\n",
              "      <th>upper_case_word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_78.txt</td>\n",
              "      <td>Yeah, I think that we’re on the right track in...</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_64.txt</td>\n",
              "      <td>There are only two countries in the world that...</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_96.txt</td>\n",
              "      <td>Sure, there’s one point we’re really missing o...</td>\n",
              "      <td>16</td>\n",
              "      <td>15</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_94.txt</td>\n",
              "      <td>I’m not wedded to a particular solution, but I...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_3.txt</td>\n",
              "      <td>There’s a larger battle going on on the planet...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     file_name  ... upper_case_word_count\n",
              "0  test_78.txt  ...                     3\n",
              "1  test_64.txt  ...                     2\n",
              "2  test_96.txt  ...                     0\n",
              "3  test_94.txt  ...                     1\n",
              "4   test_3.txt  ...                     1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc5PGbY8DPDY",
        "colab_type": "text"
      },
      "source": [
        "Creating function to get top 11 instances of the predicted labels and to move row from test to train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb-bDeyiUuwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get top instances \n",
        "def getTopInstances(test, testFeature, total):\n",
        "  prob_predicted = {}\n",
        "  k = 0\n",
        "  for i, row in test.iterrows():\n",
        "    prob_dict = dict(zip(clf_semi.classes_, clf_semi.predict_proba(testFeature)[k]))\n",
        "    results = list(map(lambda x: (x[0], x[1]), sorted(zip(clf_semi.classes_, clf_semi.predict_proba(testFeature)[k]), key=lambda x: x[1], reverse=True)))\n",
        "    prob_predicted[i] = results[0]\n",
        "    k += 1\n",
        "  print(\"The class and their associated probability\", prob_predicted)\n",
        "  sort_prob = sorted(prob_predicted.keys(), key=lambda x: prob_predicted[x][1], reverse=True)[:total]\n",
        "  return(sort_prob, prob_predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18LvbFTaX94O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get top 10 index and classes\n",
        "def addTopTest(test, train, prob_class, prob_pred):\n",
        "  #find label class and index to add\n",
        "  k = 1\n",
        "  l = 11\n",
        "  for i in prob_class:\n",
        "    curr_row = []\n",
        "    #remove from the test features\n",
        "    curr_s= test.loc[[i]]\n",
        "    #drop these rows from the data frame\n",
        "    test = test.drop([i])\n",
        "    clean = cleanQuotes(curr_s.Quotes.item())\n",
        "    final_clean = lemmatizeQuotes(clean)\n",
        "    curr_row.append([prob_pred[i][0], curr_s.Quotes.item(), clean, final_clean, curr_s.char_count.item(), curr_s.word_count.item(), curr_s.word_density.item(),\\\n",
        "                     curr_s.punctuation_count.item(), curr_s.title_word_count.item(), curr_s.upper_case_word_count.item()])\n",
        "    #add curr_row to training df\n",
        "    train = train.append(pd.DataFrame(curr_row, columns = train.columns))\n",
        "    print(\"Adding row \",i, \" ----- \", k, \"/\", l)\n",
        "    k += 1\n",
        "    #print(\"Adding row\\n\",curr_row)\n",
        "    #print(\"\\nShape after adding row\", train.shape)\n",
        "  return(train, test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clQWzP6yP0u2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f27d4ad9-e362-492b-efeb-bce45a0c5f1c"
      },
      "source": [
        "pc, pp = getTopInstances(dup_test, test_features, 11)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The class and their associated probability {0: ('BUTTIGIEG', 0.7544077826360094), 1: ('YANG', 0.46918590737837257), 2: ('STEYER', 0.37798623173465984), 3: ('BUTTIGIEG', 0.287684393177938), 4: ('GABBARD', 0.31403338198006103), 5: ('BUTTIGIEG', 0.5138170881762653), 6: ('WARREN', 0.3976050715524329), 7: ('SANDERS', 0.43015365352190665), 8: ('GABBARD', 0.5181363258244225), 9: ('BUTTIGIEG', 0.40003449674772407), 10: ('BOOKER', 0.7347451102795245), 11: ('BUTTIGIEG', 0.7684996809736496), 12: ('GABBARD', 0.6342615284364211), 13: ('BUTTIGIEG', 0.8818786647200211), 14: ('KLOBUCHAR', 0.5122780545439825), 15: ('WARREN', 0.43394211598820437), 16: ('YANG', 0.7740093314386182), 17: ('SANDERS', 0.32054577481059754), 18: ('BUTTIGIEG', 0.3351205071466052), 19: ('YANG', 0.25276003153668297), 20: ('WARREN', 0.7311497270790818), 21: ('BOOKER', 0.40578256573548105), 22: ('BUTTIGIEG', 0.39972289314746695), 23: ('BIDEN', 0.6736513068972034), 24: ('HARRIS', 0.7034310204650062), 25: ('SANDERS', 0.4833090076453091), 26: ('OROURKE', 0.44732783487521594), 27: ('HARRIS', 0.34368183677905284), 28: ('YANG', 0.2966142229455839), 29: ('GABBARD', 0.22924204977156465), 30: ('HARRIS', 0.7785242966552427), 31: ('STEYER', 0.40824896417578693), 32: ('GABBARD', 0.6422311544619685), 33: ('SANDERS', 0.5190237838956004), 34: ('WARREN', 0.3709495555242734), 35: ('BUTTIGIEG', 0.3045555247335106), 36: ('WARREN', 0.4312205960496748), 37: ('OROURKE', 0.6730307693590359), 38: ('BOOKER', 0.9185121174642663), 39: ('WARREN', 0.49604467536686575), 40: ('WARREN', 0.3554347425160319), 41: ('YANG', 0.32607023744590385), 42: ('KLOBUCHAR', 0.5304255449490591), 43: ('BUTTIGIEG', 0.3196387731848986), 44: ('BOOKER', 0.7804698295614751), 45: ('HARRIS', 0.6598069530551387), 46: ('BIDEN', 0.4986471053438005), 47: ('SANDERS', 0.5858036395665187), 48: ('WARREN', 0.4164372911587613), 49: ('KLOBUCHAR', 0.2756180716620107), 50: ('BUTTIGIEG', 0.4639464672529777), 51: ('YANG', 0.21612265987496282), 52: ('KLOBUCHAR', 0.8007076177628042), 53: ('BIDEN', 0.4354956301626594), 54: ('KLOBUCHAR', 0.4391515730603531), 55: ('KLOBUCHAR', 0.6184646448665704), 56: ('KLOBUCHAR', 0.6256034760329394), 57: ('SANDERS', 0.6949920450206749), 58: ('WARREN', 0.6549770610066503), 59: ('CASTRO', 0.3185064313779743), 60: ('WARREN', 0.3237782761377741), 61: ('KLOBUCHAR', 0.23627082540600802), 62: ('BUTTIGIEG', 0.7091579761958319), 63: ('OROURKE', 0.5566400538294911), 64: ('WARREN', 0.31942667316386986), 65: ('BUTTIGIEG', 0.23536288420188828), 66: ('KLOBUCHAR', 0.46152879268748087), 67: ('OROURKE', 0.4479722433088861), 68: ('BUTTIGIEG', 0.33163154993733707), 69: ('WARREN', 0.21571430916024628), 70: ('HARRIS', 0.5794733801989699), 71: ('OROURKE', 0.5979416856919577), 72: ('BUTTIGIEG', 0.6139569403406169), 73: ('BIDEN', 0.30349453921849157), 74: ('SANDERS', 0.5980853875507027), 75: ('BUTTIGIEG', 0.42171305409837145), 76: ('WARREN', 0.31534485439052906), 77: ('SANDERS', 0.2561013663097867), 78: ('YANG', 0.4199831005031079), 79: ('BOOKER', 0.6778780852870924), 80: ('WARREN', 0.3492402592679729), 81: ('BUTTIGIEG', 0.3011604146411137), 82: ('SANDERS', 0.31784433942210055), 83: ('BIDEN', 0.49993146763097007), 84: ('SANDERS', 0.43561127238614467), 85: ('STEYER', 0.3543590515882439), 86: ('KLOBUCHAR', 0.4868666636301547), 87: ('OROURKE', 0.5508525013720047), 88: ('BOOKER', 0.2926398893014137), 89: ('KLOBUCHAR', 0.5987437845386877), 90: ('BUTTIGIEG', 0.589564854335018), 91: ('BIDEN', 0.882537858777352), 92: ('BIDEN', 0.9130616561771373), 93: ('BOOKER', 0.31542676230169436), 94: ('BUTTIGIEG', 0.5994495221875374), 95: ('WARREN', 0.5488395834590035), 96: ('YANG', 0.47709318651443927), 97: ('WARREN', 0.20728517485935444), 98: ('WARREN', 0.36605541472844405), 99: ('BOOKER', 0.33506821623815153), 100: ('OROURKE', 0.8356941651688361), 101: ('WARREN', 0.534932918847677), 102: ('BUTTIGIEG', 0.3931069036109434), 103: ('KLOBUCHAR', 0.5330303470783226), 104: ('WARREN', 0.4013586655691041), 105: ('GABBARD', 0.5359306190953955), 106: ('YANG', 0.4466066838209394), 107: ('SANDERS', 0.4855747801906984), 108: ('CASTRO', 0.29299260818430206), 109: ('BUTTIGIEG', 0.4385777511441536), 110: ('WARREN', 0.41188513990816833)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "721Wq5zIET4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "7ed69a49-99b5-40d7-c80b-dae06e2e303e"
      },
      "source": [
        "#generate new train and test\n",
        "dup_train, dup_test = addTopTest(dup_test, dup_train, pc, pp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adding row  38  -----  1 / 11\n",
            "Adding row  92  -----  2 / 11\n",
            "Adding row  91  -----  3 / 11\n",
            "Adding row  13  -----  4 / 11\n",
            "Adding row  100  -----  5 / 11\n",
            "Adding row  52  -----  6 / 11\n",
            "Adding row  44  -----  7 / 11\n",
            "Adding row  30  -----  8 / 11\n",
            "Adding row  16  -----  9 / 11\n",
            "Adding row  11  -----  10 / 11\n",
            "Adding row  0  -----  11 / 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7rCE6KgItsd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "0713a69b-43d4-44aa-fb8e-12c5a338f2bd"
      },
      "source": [
        "print(\"The shape of train:\", dup_train.shape, \"\\ntest:\", dup_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of train: (539, 10) \n",
            "test: (100, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fbfTCKWmITA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vectorize and then \n",
        "#vectorize train and test both \n",
        "def generateFeatures(train, test):\n",
        "  semi_train_x = vectorizer.transform(train['final_clean'])\n",
        "  semi_test_x = vectorizer.transform(test.Quotes)\n",
        "  semi_features = [f_ for f_ in train.columns\\\n",
        "                  if f_ in [\"char_count\", \"word_count\", \"word_density\", 'punctuation_count','title_word_count', 'upper_case_word_count']]\n",
        "  print(\"The shape of train:\", semi_train_x.shape, \"\\ntest:\", semi_train_x .shape)\n",
        "\n",
        "\n",
        "  for f in semi_features:\n",
        "      all_cut = pd.cut(pd.concat([train[f], test[f]], axis=0), bins=20, labels=False, retbins=False)\n",
        "      train[f] = all_cut.values[:train.shape[0]]\n",
        "      test[f] = all_cut.values[train.shape[0]:]\n",
        "\n",
        "  train_dup_features = train[semi_features].values\n",
        "  test_dup_features = test[semi_features].values\n",
        "  dup_train_features = hstack([semi_train_x, train_dup_features]) \n",
        "  dup_test_features = hstack([semi_test_x, test_dup_features])\n",
        "\n",
        "  return(dup_train_features, dup_test_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBRMF6e9oXE3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "8905b25c-0849-4e1d-934b-26a5996d1185"
      },
      "source": [
        "#generate feature for new test train\n",
        "curr_train_feature, curr_test_feature = generateFeatures(dup_train, dup_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of train: (539, 432) \n",
            "test: (539, 432)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEHMGmGOq3qS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "eef8c617-ff46-4284-97b9-e868483172c3"
      },
      "source": [
        "clf_semi.fit(curr_train_feature,dup_train.label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDN5zdYLstJq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "820ab82f-6455-4ebf-aff8-37e3f9fda4b1"
      },
      "source": [
        "accuracy = []\n",
        "ac = clf_semi.score(train_features, train_df.label)\n",
        "accuracy.append(ac)\n",
        "print(\"The accuracy of the model after 1st iteration on the updated train data is\" , clf_semi.score(curr_train_feature, dup_train.label) * 100, \"%\" )\n",
        "print(\"The accuracy of the model after 1st iteration on the original train data is\" ,ac * 100, \"%\" )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the model after 1st iteration on the updated train data is 97.21706864564007 %\n",
            "The accuracy of the model after 1st iteration on the original train data is 97.1590909090909 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcJlOhrLu2GN",
        "colab_type": "text"
      },
      "source": [
        "The accuracy of the model for the original train data is 97.15% which is an increase from 96.96% which observed in part 2 or at the start of part 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4fR6fNFS3qV",
        "colab_type": "text"
      },
      "source": [
        "#### 15. 9 more iteration and plotting performance in terms of accuracy\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PKdP-lUSmPY",
        "colab_type": "text"
      },
      "source": [
        "15. Now, repeat the process above 9 more times, each time adding an additional 10% of the test data for which the labels have the highest probability (note that this may result in different test observations being included from one iteration to the next). After each iteration, note the performance on the original training data set. Generate a plot which shows the percentage of the test dataset used on the X-axis and the classification accuracy on the original training dataset on the Y-axis. There should be 11 points for this plot, ranging from X = 0% to X = 100%, inclusive. What does the plot look like? Comment on what you see. (Note: this type of semi-supervised learning can very much be hit-or-miss. This type of learning doesn’t always yield benefits).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7WyRtQm6PtJX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a8b05ba-4766-4eaa-f051-3b6253f778e7"
      },
      "source": [
        "for ix in range(2, 11):\n",
        "  print(\"===============================\" , ix, \"===================================\")\n",
        "  if ix == 10:\n",
        "    pc, pp = getTopInstances(dup_test, curr_test_feature, 12)\n",
        "  else:\n",
        "    pc, pp = getTopInstances(dup_test, curr_test_feature, 11)\n",
        "  #generate new train and test\n",
        "  dup_train, dup_test = addTopTest(dup_test, dup_train, pc, pp)\n",
        "  print(\"The shape of train:\", dup_train.shape, \"\\ntest:\", dup_test.shape)\n",
        "  #generate feature for new test train\n",
        "  curr_train_feature, curr_test_feature = generateFeatures(dup_train, dup_test)\n",
        "  clf_semi.fit(curr_train_feature,dup_train.label)\n",
        "  ac = clf_semi.score(train_features, train_df.label)\n",
        "  accuracy.append(ac)\n",
        "  print(\"The accuracy of the model after\", ix,\" iteration on the update train data is\" , clf_semi.score(curr_train_feature, dup_train.label) * 100, \"%\" )\n",
        "  print(\"The accuracy of the model after\", ix,\"iteration on the original train data is\" ,ac * 100, \"%\" )\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=============================== 2 ===================================\n",
            "The class and their associated probability {1: ('HARRIS', 0.5370140363637693), 2: ('STEYER', 0.3609973954720476), 3: ('BUTTIGIEG', 0.26109378674812117), 4: ('GABBARD', 0.31323626908301777), 5: ('BUTTIGIEG', 0.5630621011811736), 6: ('WARREN', 0.4029957904999807), 7: ('SANDERS', 0.40985015405753555), 8: ('GABBARD', 0.539144963441624), 9: ('BUTTIGIEG', 0.38860779273557555), 10: ('BOOKER', 0.743482491689109), 12: ('GABBARD', 0.6600611921155172), 14: ('KLOBUCHAR', 0.5288514316303533), 15: ('WARREN', 0.4530261530430109), 17: ('SANDERS', 0.2896144325127799), 18: ('SANDERS', 0.22473656016250645), 19: ('YANG', 0.3172596733196375), 20: ('WARREN', 0.7336472555614226), 21: ('BOOKER', 0.3968275081500908), 22: ('BUTTIGIEG', 0.42344182574260775), 23: ('BIDEN', 0.6668716120662769), 24: ('HARRIS', 0.6059779887722132), 25: ('SANDERS', 0.4992663218357219), 26: ('OROURKE', 0.49002236599174126), 27: ('HARRIS', 0.35758147625509457), 28: ('YANG', 0.34014314154458103), 29: ('GABBARD', 0.23382604498478415), 31: ('STEYER', 0.4293342516928104), 32: ('GABBARD', 0.7138203037314845), 33: ('SANDERS', 0.5213131641519241), 34: ('WARREN', 0.384366206904137), 35: ('BUTTIGIEG', 0.34313905765217706), 36: ('WARREN', 0.4588256975944227), 37: ('OROURKE', 0.6998850287513756), 39: ('WARREN', 0.514435149059772), 40: ('WARREN', 0.3584555728122667), 41: ('YANG', 0.3208497745792273), 42: ('KLOBUCHAR', 0.5538862185958262), 43: ('BUTTIGIEG', 0.29634501138548447), 45: ('HARRIS', 0.6281634631845984), 46: ('BIDEN', 0.49770688341171937), 47: ('SANDERS', 0.5938204415212354), 48: ('WARREN', 0.41497405771260004), 49: ('KLOBUCHAR', 0.303936478103376), 50: ('BUTTIGIEG', 0.4406716066296316), 51: ('YANG', 0.21590650020326455), 53: ('BIDEN', 0.4140139668502552), 54: ('KLOBUCHAR', 0.4173252010450788), 55: ('KLOBUCHAR', 0.623216799024035), 56: ('KLOBUCHAR', 0.6279623787476625), 57: ('SANDERS', 0.7095353071233732), 58: ('WARREN', 0.5695020315836283), 59: ('CASTRO', 0.3559137431087011), 60: ('WARREN', 0.311820258906258), 61: ('KLOBUCHAR', 0.22146570212551903), 62: ('BUTTIGIEG', 0.6209612414141372), 63: ('OROURKE', 0.5698860242334245), 64: ('WARREN', 0.31513254277671177), 65: ('BUTTIGIEG', 0.248269079074105), 66: ('KLOBUCHAR', 0.43134401834931224), 67: ('OROURKE', 0.4465900233765473), 68: ('BUTTIGIEG', 0.3464021887779011), 69: ('WARREN', 0.2179717407415344), 70: ('HARRIS', 0.5919206567521934), 71: ('OROURKE', 0.6068127188021205), 72: ('BUTTIGIEG', 0.6256764117274048), 73: ('CASTRO', 0.30954018087181173), 74: ('SANDERS', 0.591889633643461), 75: ('BUTTIGIEG', 0.40176917305098836), 76: ('WARREN', 0.31609152284073905), 77: ('SANDERS', 0.27162166490462963), 78: ('YANG', 0.4177537999920044), 79: ('BOOKER', 0.7112217151098607), 80: ('WARREN', 0.3699164653736132), 81: ('BIDEN', 0.2238213626754886), 82: ('SANDERS', 0.30207019860946105), 83: ('BIDEN', 0.4985305547924018), 84: ('SANDERS', 0.4360443048162872), 85: ('STEYER', 0.36219462532203256), 86: ('KLOBUCHAR', 0.4889678837551836), 87: ('OROURKE', 0.4767217489502375), 88: ('BOOKER', 0.2932966359975495), 89: ('KLOBUCHAR', 0.5741088237951686), 90: ('BUTTIGIEG', 0.6127832078517927), 93: ('BOOKER', 0.34934999962701285), 94: ('BUTTIGIEG', 0.5851308426181081), 95: ('WARREN', 0.563766627465627), 96: ('YANG', 0.4770124242946464), 97: ('BOOKER', 0.20766768498332086), 98: ('WARREN', 0.3746023654584493), 99: ('BOOKER', 0.35797824566208253), 101: ('WARREN', 0.5450265778870491), 102: ('BUTTIGIEG', 0.3853320436807269), 103: ('KLOBUCHAR', 0.5038842109689654), 104: ('WARREN', 0.4041799978410497), 105: ('GABBARD', 0.5400733375756192), 106: ('YANG', 0.4458651561572757), 107: ('SANDERS', 0.49640843194124795), 108: ('CASTRO', 0.35392406001458165), 109: ('BUTTIGIEG', 0.43368276843707304), 110: ('WARREN', 0.42949882793330346)}\n",
            "Adding row  10  -----  1 / 11\n",
            "Adding row  20  -----  2 / 11\n",
            "Adding row  32  -----  3 / 11\n",
            "Adding row  79  -----  4 / 11\n",
            "Adding row  57  -----  5 / 11\n",
            "Adding row  37  -----  6 / 11\n",
            "Adding row  23  -----  7 / 11\n",
            "Adding row  12  -----  8 / 11\n",
            "Adding row  45  -----  9 / 11\n",
            "Adding row  56  -----  10 / 11\n",
            "Adding row  72  -----  11 / 11\n",
            "The shape of train: (550, 10) \n",
            "test: (89, 8)\n",
            "The shape of train: (550, 432) \n",
            "test: (550, 432)\n",
            "The accuracy of the model after 2  iteration on the update train data is 97.0909090909091 %\n",
            "The accuracy of the model after 2 iteration on the original train data is 96.96969696969697 %\n",
            "=============================== 3 ===================================\n",
            "The class and their associated probability {1: ('HARRIS', 0.42817002947831406), 2: ('STEYER', 0.35875115351295106), 3: ('BUTTIGIEG', 0.25250938058870015), 4: ('GABBARD', 0.304360554904123), 5: ('BUTTIGIEG', 0.6014679670506256), 6: ('WARREN', 0.3939454268558852), 7: ('SANDERS', 0.42411135698565267), 8: ('GABBARD', 0.5751537988006858), 9: ('BUTTIGIEG', 0.3846304760221876), 14: ('KLOBUCHAR', 0.5144482817854131), 15: ('WARREN', 0.44783159487767354), 17: ('SANDERS', 0.3070936756718111), 18: ('HARRIS', 0.23294644527429126), 19: ('YANG', 0.25238368138757106), 21: ('BOOKER', 0.420298255106735), 22: ('BUTTIGIEG', 0.4523070997249416), 24: ('HARRIS', 0.6480761738880968), 25: ('SANDERS', 0.511297356337046), 26: ('OROURKE', 0.4763245654379684), 27: ('HARRIS', 0.4902417016556435), 28: ('YANG', 0.3806673502443419), 29: ('HARRIS', 0.4032211125989962), 31: ('STEYER', 0.5502985926950364), 33: ('SANDERS', 0.5192178765771905), 34: ('WARREN', 0.4072074627527801), 35: ('BUTTIGIEG', 0.31089072055834577), 36: ('WARREN', 0.4674947105164272), 39: ('WARREN', 0.5373215399353065), 40: ('WARREN', 0.3662810196754983), 41: ('YANG', 0.31730844431506267), 42: ('KLOBUCHAR', 0.4392134752322669), 43: ('BUTTIGIEG', 0.27325765385315726), 46: ('BIDEN', 0.5260917195964718), 47: ('SANDERS', 0.5792497313425675), 48: ('WARREN', 0.4172972971620432), 49: ('KLOBUCHAR', 0.3099652024848012), 50: ('BUTTIGIEG', 0.4055521604557436), 51: ('YANG', 0.20227045939203586), 53: ('BIDEN', 0.3775253120589487), 54: ('KLOBUCHAR', 0.3911925983040426), 55: ('HARRIS', 0.6093154378711428), 58: ('WARREN', 0.575448825185415), 59: ('CASTRO', 0.3845840366973791), 60: ('WARREN', 0.32007417646124997), 61: ('BOOKER', 0.33873323934925426), 62: ('BUTTIGIEG', 0.7133012902245472), 63: ('OROURKE', 0.573314509220946), 64: ('WARREN', 0.27527222096175735), 65: ('BUTTIGIEG', 0.23990561909056024), 66: ('KLOBUCHAR', 0.42204126466444924), 67: ('OROURKE', 0.4419123970348143), 68: ('BUTTIGIEG', 0.3598161900750843), 69: ('WARREN', 0.23398975397645388), 70: ('HARRIS', 0.6130556274039561), 71: ('OROURKE', 0.6812436436899688), 73: ('CASTRO', 0.318253744707877), 74: ('SANDERS', 0.5126374442243801), 75: ('BUTTIGIEG', 0.397356683431477), 76: ('WARREN', 0.3240360085930677), 77: ('YANG', 0.25741814245652006), 78: ('YANG', 0.4751331307328186), 80: ('WARREN', 0.39083262849379585), 81: ('YANG', 0.24361847610956308), 82: ('SANDERS', 0.2815263643971605), 83: ('BIDEN', 0.5405917760624259), 84: ('SANDERS', 0.43944499385544245), 85: ('STEYER', 0.3317216830394256), 86: ('KLOBUCHAR', 0.37398278315300315), 87: ('OROURKE', 0.4458291755220269), 88: ('BOOKER', 0.29124689420503413), 89: ('KLOBUCHAR', 0.5541223757185786), 90: ('BUTTIGIEG', 0.6277391113881212), 93: ('BOOKER', 0.31760080563037796), 94: ('BUTTIGIEG', 0.61448606601296), 95: ('WARREN', 0.5881100873185194), 96: ('YANG', 0.47793868786982113), 97: ('SANDERS', 0.21298107298179556), 98: ('WARREN', 0.36941434282028607), 99: ('KLOBUCHAR', 0.34757440490885744), 101: ('WARREN', 0.4498938088720594), 102: ('BUTTIGIEG', 0.38493937734464845), 103: ('KLOBUCHAR', 0.4838037662009036), 104: ('WARREN', 0.42049648085769725), 105: ('BUTTIGIEG', 0.36171221466446263), 106: ('YANG', 0.4720213470055178), 107: ('SANDERS', 0.5302253354011633), 108: ('CASTRO', 0.2988156846850093), 109: ('BUTTIGIEG', 0.3937867767859148), 110: ('WARREN', 0.44320657723565177)}\n",
            "Adding row  62  -----  1 / 11\n",
            "Adding row  71  -----  2 / 11\n",
            "Adding row  24  -----  3 / 11\n",
            "Adding row  90  -----  4 / 11\n",
            "Adding row  94  -----  5 / 11\n",
            "Adding row  70  -----  6 / 11\n",
            "Adding row  55  -----  7 / 11\n",
            "Adding row  5  -----  8 / 11\n",
            "Adding row  95  -----  9 / 11\n",
            "Adding row  47  -----  10 / 11\n",
            "Adding row  58  -----  11 / 11\n",
            "The shape of train: (561, 10) \n",
            "test: (78, 8)\n",
            "The shape of train: (561, 432) \n",
            "test: (561, 432)\n",
            "The accuracy of the model after 3  iteration on the update train data is 97.14795008912655 %\n",
            "The accuracy of the model after 3 iteration on the original train data is 96.96969696969697 %\n",
            "=============================== 4 ===================================\n",
            "The class and their associated probability {1: ('HARRIS', 0.42039807901562226), 2: ('STEYER', 0.38536444493531435), 3: ('BUTTIGIEG', 0.26942848672948944), 4: ('GABBARD', 0.3145492984076465), 6: ('WARREN', 0.3844888270193263), 7: ('SANDERS', 0.5453624277577332), 8: ('GABBARD', 0.5162744918680636), 9: ('BUTTIGIEG', 0.40694560421902753), 14: ('KLOBUCHAR', 0.47296455758414696), 15: ('WARREN', 0.4310466282622543), 17: ('OROURKE', 0.26615566439255967), 18: ('BUTTIGIEG', 0.2337336020737013), 19: ('YANG', 0.30201362002202836), 21: ('BOOKER', 0.4262115486730821), 22: ('BUTTIGIEG', 0.46051584609287216), 25: ('SANDERS', 0.47938358236715356), 26: ('OROURKE', 0.4802094059813968), 27: ('HARRIS', 0.5632866771972782), 28: ('YANG', 0.4000351771660146), 29: ('GABBARD', 0.28977834336830405), 31: ('STEYER', 0.5594422553876975), 33: ('SANDERS', 0.5416619954010555), 34: ('WARREN', 0.3932168102236687), 35: ('BUTTIGIEG', 0.31456614763548785), 36: ('WARREN', 0.4816762501505739), 39: ('WARREN', 0.5123628272480119), 40: ('WARREN', 0.38936680040233834), 41: ('YANG', 0.3300911883413069), 42: ('HARRIS', 0.39435032915622814), 43: ('BUTTIGIEG', 0.2966976662203693), 46: ('BIDEN', 0.4507442109180402), 48: ('WARREN', 0.424953262539507), 49: ('KLOBUCHAR', 0.30469060817160776), 50: ('BUTTIGIEG', 0.4510005544577767), 51: ('HARRIS', 0.2189678954295823), 53: ('BIDEN', 0.3483973947780045), 54: ('HARRIS', 0.38199671389285605), 59: ('CASTRO', 0.3464563394835565), 60: ('WARREN', 0.3301818316252092), 61: ('BOOKER', 0.32949312873288605), 63: ('OROURKE', 0.568235373869989), 64: ('WARREN', 0.261533213565303), 65: ('BUTTIGIEG', 0.24210588435673516), 66: ('BIDEN', 0.3662121771823739), 67: ('OROURKE', 0.4014140549153286), 68: ('BUTTIGIEG', 0.39276512562642746), 69: ('WARREN', 0.227788079885039), 73: ('CASTRO', 0.316369441290389), 74: ('SANDERS', 0.5933299586328503), 75: ('BUTTIGIEG', 0.44106943904072776), 76: ('WARREN', 0.31658150490991105), 77: ('WARREN', 0.2878101918020231), 78: ('YANG', 0.46147970592503473), 80: ('WARREN', 0.38209340943542447), 81: ('YANG', 0.26080482711265224), 82: ('BUTTIGIEG', 0.24953463954087002), 83: ('BIDEN', 0.5288926371755149), 84: ('SANDERS', 0.46754588435545336), 85: ('STEYER', 0.32754817692085086), 86: ('KLOBUCHAR', 0.3731466568471458), 87: ('OROURKE', 0.39916054257130595), 88: ('BOOKER', 0.28347961114157044), 89: ('KLOBUCHAR', 0.548364208370074), 93: ('BOOKER', 0.29217742196974544), 96: ('YANG', 0.47973918546170874), 97: ('WARREN', 0.2178406101062579), 98: ('WARREN', 0.3915972798577084), 99: ('KLOBUCHAR', 0.32942509418235993), 101: ('WARREN', 0.4734520707644509), 102: ('BUTTIGIEG', 0.42226276116911476), 103: ('HARRIS', 0.4841751166383631), 104: ('WARREN', 0.4178968466046884), 105: ('BUTTIGIEG', 0.3476245770230504), 106: ('YANG', 0.520149695988044), 107: ('SANDERS', 0.5470445725825092), 108: ('CASTRO', 0.2791978814349119), 109: ('BUTTIGIEG', 0.4376169992844998), 110: ('WARREN', 0.46303677660674)}\n",
            "Adding row  74  -----  1 / 11\n",
            "Adding row  63  -----  2 / 11\n",
            "Adding row  27  -----  3 / 11\n",
            "Adding row  31  -----  4 / 11\n",
            "Adding row  89  -----  5 / 11\n",
            "Adding row  107  -----  6 / 11\n",
            "Adding row  7  -----  7 / 11\n",
            "Adding row  33  -----  8 / 11\n",
            "Adding row  83  -----  9 / 11\n",
            "Adding row  106  -----  10 / 11\n",
            "Adding row  8  -----  11 / 11\n",
            "The shape of train: (572, 10) \n",
            "test: (67, 8)\n",
            "The shape of train: (572, 432) \n",
            "test: (572, 432)\n",
            "The accuracy of the model after 4  iteration on the update train data is 97.2027972027972 %\n",
            "The accuracy of the model after 4 iteration on the original train data is 96.96969696969697 %\n",
            "=============================== 5 ===================================\n",
            "The class and their associated probability {1: ('HARRIS', 0.3430675904032652), 2: ('STEYER', 0.3803871153710871), 3: ('BUTTIGIEG', 0.22748419076937548), 4: ('GABBARD', 0.28655228176389463), 6: ('WARREN', 0.39553644089378914), 9: ('BUTTIGIEG', 0.35907607666390423), 14: ('KLOBUCHAR', 0.5432135007711287), 15: ('BIDEN', 0.4088793820752294), 17: ('SANDERS', 0.3521246165882808), 18: ('HARRIS', 0.2767174336141979), 19: ('YANG', 0.30616553111335354), 21: ('BOOKER', 0.4405671268519999), 22: ('BUTTIGIEG', 0.49705978215331714), 25: ('SANDERS', 0.5531710886063312), 26: ('OROURKE', 0.48697091065538844), 28: ('YANG', 0.35407795775174294), 29: ('GABBARD', 0.30283929385130265), 34: ('WARREN', 0.34790424668027176), 35: ('BUTTIGIEG', 0.2942276852788879), 36: ('WARREN', 0.5207619472109395), 39: ('WARREN', 0.5385851027217704), 40: ('WARREN', 0.41021511784477316), 41: ('YANG', 0.37022114050290117), 42: ('HARRIS', 0.3923467836374493), 43: ('BUTTIGIEG', 0.24435317899014378), 46: ('HARRIS', 0.4241343774555368), 48: ('WARREN', 0.42548875573198724), 49: ('KLOBUCHAR', 0.3043772999211029), 50: ('BUTTIGIEG', 0.3866842345900528), 51: ('HARRIS', 0.22540022278308317), 53: ('BIDEN', 0.3009716985193386), 54: ('HARRIS', 0.3811709273432878), 59: ('CASTRO', 0.34920516805859586), 60: ('WARREN', 0.31055741155600175), 61: ('BOOKER', 0.3144885906247891), 64: ('SANDERS', 0.409886043776087), 65: ('BUTTIGIEG', 0.20188023625712298), 66: ('BIDEN', 0.38171006074528024), 67: ('OROURKE', 0.4268335588121277), 68: ('BUTTIGIEG', 0.370538551210657), 69: ('WARREN', 0.2347432951279223), 73: ('BIDEN', 0.32373348687568543), 75: ('BUTTIGIEG', 0.4048953821681244), 76: ('WARREN', 0.3266995323087283), 77: ('SANDERS', 0.34702354585525735), 78: ('YANG', 0.4360474445228999), 80: ('WARREN', 0.38481031585149017), 81: ('YANG', 0.29779695839965015), 82: ('BUTTIGIEG', 0.21699727969184524), 84: ('SANDERS', 0.5082039992556935), 85: ('STEYER', 0.3032233903997426), 86: ('KLOBUCHAR', 0.3777814984792786), 87: ('OROURKE', 0.3482289404901616), 88: ('BOOKER', 0.29870292320702657), 93: ('BOOKER', 0.2838084451377065), 96: ('YANG', 0.48641506306665855), 97: ('KLOBUCHAR', 0.25176018949538037), 98: ('WARREN', 0.40901343836847204), 99: ('KLOBUCHAR', 0.3273501531448511), 101: ('WARREN', 0.5004280528875491), 102: ('BUTTIGIEG', 0.39159843581709003), 103: ('HARRIS', 0.49063295466309587), 104: ('WARREN', 0.45042929725398173), 105: ('GABBARD', 0.42950655770504564), 108: ('HARRIS', 0.24954108194172253), 109: ('BUTTIGIEG', 0.3331102382815286), 110: ('WARREN', 0.4375984324262172)}\n",
            "Adding row  25  -----  1 / 11\n",
            "Adding row  14  -----  2 / 11\n",
            "Adding row  39  -----  3 / 11\n",
            "Adding row  36  -----  4 / 11\n",
            "Adding row  84  -----  5 / 11\n",
            "Adding row  101  -----  6 / 11\n",
            "Adding row  22  -----  7 / 11\n",
            "Adding row  103  -----  8 / 11\n",
            "Adding row  26  -----  9 / 11\n",
            "Adding row  96  -----  10 / 11\n",
            "Adding row  104  -----  11 / 11\n",
            "The shape of train: (583, 10) \n",
            "test: (56, 8)\n",
            "The shape of train: (583, 432) \n",
            "test: (583, 432)\n",
            "The accuracy of the model after 5  iteration on the update train data is 96.91252144082333 %\n",
            "The accuracy of the model after 5 iteration on the original train data is 96.5909090909091 %\n",
            "=============================== 6 ===================================\n",
            "The class and their associated probability {1: ('YANG', 0.38025151944098273), 2: ('STEYER', 0.42161726705170055), 3: ('WARREN', 0.22999379017372776), 4: ('GABBARD', 0.3115746333405648), 6: ('WARREN', 0.40525086995031573), 9: ('BUTTIGIEG', 0.34643403335076967), 15: ('WARREN', 0.45524287230278676), 17: ('SANDERS', 0.2946586406325232), 18: ('HARRIS', 0.30774821743459185), 19: ('HARRIS', 0.4982763475429643), 21: ('BOOKER', 0.4431684953930343), 28: ('YANG', 0.3615780725761001), 29: ('GABBARD', 0.31097668434900033), 34: ('WARREN', 0.4422785368021958), 35: ('BUTTIGIEG', 0.3416381223802454), 40: ('WARREN', 0.4470984582237189), 41: ('YANG', 0.37482248061601753), 42: ('HARRIS', 0.440548063349033), 43: ('BUTTIGIEG', 0.21971128627382902), 46: ('HARRIS', 0.4478821389597354), 48: ('WARREN', 0.40555251251605384), 49: ('KLOBUCHAR', 0.2885841738044967), 50: ('BUTTIGIEG', 0.38625716324536), 51: ('HARRIS', 0.29885338277129553), 53: ('HARRIS', 0.35236080097865075), 54: ('HARRIS', 0.4046195341075571), 59: ('WARREN', 0.35597352602071797), 60: ('WARREN', 0.33423801599887043), 61: ('BOOKER', 0.31284076521276205), 64: ('SANDERS', 0.382909261431372), 65: ('BUTTIGIEG', 0.19950045096685234), 66: ('BIDEN', 0.32089729168995285), 67: ('OROURKE', 0.4261481450032405), 68: ('BUTTIGIEG', 0.3568566813614509), 69: ('WARREN', 0.2641037941499305), 73: ('CASTRO', 0.322741627612829), 75: ('BUTTIGIEG', 0.41327541692836745), 76: ('WARREN', 0.34165401282751817), 77: ('SANDERS', 0.4613592275378959), 78: ('WARREN', 0.4745785556340498), 80: ('WARREN', 0.4193899116715082), 81: ('YANG', 0.29338828328155153), 82: ('YANG', 0.2690573709974847), 85: ('STEYER', 0.34386450127388296), 86: ('KLOBUCHAR', 0.48696479956059413), 87: ('HARRIS', 0.38241353293929226), 88: ('BOOKER', 0.2868135956491726), 93: ('WARREN', 0.5350943319686987), 97: ('WARREN', 0.3328366903249823), 98: ('WARREN', 0.5029740729042298), 99: ('KLOBUCHAR', 0.3323211640869335), 102: ('BUTTIGIEG', 0.3311589654947026), 105: ('GABBARD', 0.42587070189778553), 108: ('HARRIS', 0.47827750561871474), 109: ('SANDERS', 0.3424136562767418), 110: ('YANG', 0.3679761133393365)}\n",
            "Adding row  93  -----  1 / 11\n",
            "Adding row  98  -----  2 / 11\n",
            "Adding row  19  -----  3 / 11\n",
            "Adding row  86  -----  4 / 11\n",
            "Adding row  108  -----  5 / 11\n",
            "Adding row  78  -----  6 / 11\n",
            "Adding row  77  -----  7 / 11\n",
            "Adding row  15  -----  8 / 11\n",
            "Adding row  46  -----  9 / 11\n",
            "Adding row  40  -----  10 / 11\n",
            "Adding row  21  -----  11 / 11\n",
            "The shape of train: (594, 10) \n",
            "test: (45, 8)\n",
            "The shape of train: (594, 432) \n",
            "test: (594, 432)\n",
            "The accuracy of the model after 6  iteration on the update train data is 96.96969696969697 %\n",
            "The accuracy of the model after 6 iteration on the original train data is 96.5909090909091 %\n",
            "=============================== 7 ===================================\n",
            "The class and their associated probability {1: ('YANG', 0.3877451884862372), 2: ('STEYER', 0.4063792488032747), 3: ('WARREN', 0.24937494706044708), 4: ('GABBARD', 0.30219353707646923), 6: ('WARREN', 0.4643109378437266), 9: ('SANDERS', 0.35627818872253697), 17: ('SANDERS', 0.28538618229917356), 18: ('HARRIS', 0.2472607935651834), 28: ('YANG', 0.3580611601303869), 29: ('HARRIS', 0.3485133471363999), 34: ('WARREN', 0.4445226502953084), 35: ('BUTTIGIEG', 0.3958912767744916), 41: ('YANG', 0.36889561589202535), 42: ('HARRIS', 0.4321130055910178), 43: ('BUTTIGIEG', 0.2274049598472829), 48: ('WARREN', 0.448362529781818), 49: ('KLOBUCHAR', 0.29705716352096684), 50: ('BUTTIGIEG', 0.3923888139508502), 51: ('HARRIS', 0.30217889354482413), 53: ('HARRIS', 0.36708810035568323), 54: ('HARRIS', 0.3979680693044444), 59: ('WARREN', 0.4007372492940516), 60: ('WARREN', 0.348398790842368), 61: ('BOOKER', 0.28790519491525746), 64: ('WARREN', 0.4032436978601495), 65: ('BUTTIGIEG', 0.18539563678262153), 66: ('HARRIS', 0.35678923775223853), 67: ('OROURKE', 0.4274459203824276), 68: ('BUTTIGIEG', 0.333991365041847), 69: ('WARREN', 0.293147742926188), 73: ('BIDEN', 0.3313209423980555), 75: ('BUTTIGIEG', 0.41677211360904004), 76: ('WARREN', 0.3830219461812917), 80: ('WARREN', 0.42525374729345117), 81: ('YANG', 0.3751641289186753), 82: ('YANG', 0.3017120858365634), 85: ('STEYER', 0.3374543923396036), 87: ('HARRIS', 0.6254287525528593), 88: ('BOOKER', 0.3173702898613027), 97: ('WARREN', 0.42239613636214995), 99: ('BOOKER', 0.32379877271127383), 102: ('BUTTIGIEG', 0.3028525817198345), 105: ('GABBARD', 0.4760320469454102), 109: ('BUTTIGIEG', 0.32496956717887865), 110: ('YANG', 0.36462733239804884)}\n",
            "Adding row  87  -----  1 / 11\n",
            "Adding row  105  -----  2 / 11\n",
            "Adding row  6  -----  3 / 11\n",
            "Adding row  48  -----  4 / 11\n",
            "Adding row  34  -----  5 / 11\n",
            "Adding row  42  -----  6 / 11\n",
            "Adding row  67  -----  7 / 11\n",
            "Adding row  80  -----  8 / 11\n",
            "Adding row  97  -----  9 / 11\n",
            "Adding row  75  -----  10 / 11\n",
            "Adding row  2  -----  11 / 11\n",
            "The shape of train: (605, 10) \n",
            "test: (34, 8)\n",
            "The shape of train: (605, 432) \n",
            "test: (605, 432)\n",
            "The accuracy of the model after 7  iteration on the update train data is 96.8595041322314 %\n",
            "The accuracy of the model after 7 iteration on the original train data is 96.40151515151516 %\n",
            "=============================== 8 ===================================\n",
            "The class and their associated probability {1: ('YANG', 0.44758404816346015), 3: ('WARREN', 0.27128235053092425), 4: ('YANG', 0.27803214946838395), 9: ('BUTTIGIEG', 0.42213226081767186), 17: ('SANDERS', 0.2740677036458099), 18: ('HARRIS', 0.3262604922945736), 28: ('GABBARD', 0.31354407753599384), 29: ('HARRIS', 0.5185315945228843), 35: ('BUTTIGIEG', 0.3439664461057635), 41: ('YANG', 0.35722637702269505), 43: ('BUTTIGIEG', 0.2741788033674176), 49: ('KLOBUCHAR', 0.30198984542711005), 50: ('BUTTIGIEG', 0.3743052128767296), 51: ('HARRIS', 0.3962070360365905), 53: ('HARRIS', 0.36697005026619167), 54: ('HARRIS', 0.40533883335085563), 59: ('WARREN', 0.41476791446738664), 60: ('WARREN', 0.41987538346425207), 61: ('BOOKER', 0.27664056552330724), 64: ('SANDERS', 0.38057577027493705), 65: ('WARREN', 0.19667444307880597), 66: ('HARRIS', 0.35542688970167463), 68: ('BUTTIGIEG', 0.43624090582269504), 69: ('WARREN', 0.3696329328157561), 73: ('CASTRO', 0.29067630940494643), 76: ('WARREN', 0.44005076895293493), 81: ('YANG', 0.35702411684531465), 82: ('YANG', 0.2888499404159565), 85: ('STEYER', 0.2964292364719374), 88: ('BOOKER', 0.28604225216633544), 99: ('KLOBUCHAR', 0.3598505821222237), 102: ('BUTTIGIEG', 0.32186575564318115), 109: ('BUTTIGIEG', 0.3296267945242912), 110: ('WARREN', 0.314106084887616)}\n",
            "Adding row  29  -----  1 / 11\n",
            "Adding row  1  -----  2 / 11\n",
            "Adding row  76  -----  3 / 11\n",
            "Adding row  68  -----  4 / 11\n",
            "Adding row  9  -----  5 / 11\n",
            "Adding row  60  -----  6 / 11\n",
            "Adding row  59  -----  7 / 11\n",
            "Adding row  54  -----  8 / 11\n",
            "Adding row  51  -----  9 / 11\n",
            "Adding row  64  -----  10 / 11\n",
            "Adding row  50  -----  11 / 11\n",
            "The shape of train: (616, 10) \n",
            "test: (23, 8)\n",
            "The shape of train: (616, 432) \n",
            "test: (616, 432)\n",
            "The accuracy of the model after 8  iteration on the update train data is 96.75324675324676 %\n",
            "The accuracy of the model after 8 iteration on the original train data is 96.21212121212122 %\n",
            "=============================== 9 ===================================\n",
            "The class and their associated probability {3: ('BUTTIGIEG', 0.29293445411278163), 4: ('YANG', 0.26800165321823255), 17: ('SANDERS', 0.3562068097306518), 18: ('BUTTIGIEG', 0.30966104150825313), 28: ('BUTTIGIEG', 0.36106991443724545), 35: ('BUTTIGIEG', 0.3405807679515756), 41: ('YANG', 0.31308256658474537), 43: ('BUTTIGIEG', 0.3258493753985057), 49: ('KLOBUCHAR', 0.2998032842559888), 53: ('HARRIS', 0.3561080309578998), 61: ('BUTTIGIEG', 0.4339403398240057), 65: ('BUTTIGIEG', 0.2307330620790289), 66: ('HARRIS', 0.40317416628921204), 69: ('WARREN', 0.4224410794886984), 73: ('BIDEN', 0.28353902096238875), 81: ('YANG', 0.3235152954712682), 82: ('HARRIS', 0.24115755002950612), 85: ('STEYER', 0.30070403177312677), 88: ('BOOKER', 0.2955826986784207), 99: ('KLOBUCHAR', 0.32542074825733536), 102: ('BUTTIGIEG', 0.26271603880969163), 109: ('BUTTIGIEG', 0.510615017886128), 110: ('YANG', 0.30583500170782074)}\n",
            "Adding row  109  -----  1 / 11\n",
            "Adding row  61  -----  2 / 11\n",
            "Adding row  69  -----  3 / 11\n",
            "Adding row  66  -----  4 / 11\n",
            "Adding row  28  -----  5 / 11\n",
            "Adding row  17  -----  6 / 11\n",
            "Adding row  53  -----  7 / 11\n",
            "Adding row  35  -----  8 / 11\n",
            "Adding row  43  -----  9 / 11\n",
            "Adding row  99  -----  10 / 11\n",
            "Adding row  81  -----  11 / 11\n",
            "The shape of train: (627, 10) \n",
            "test: (12, 8)\n",
            "The shape of train: (627, 432) \n",
            "test: (627, 432)\n",
            "The accuracy of the model after 9  iteration on the update train data is 96.96969696969697 %\n",
            "The accuracy of the model after 9 iteration on the original train data is 96.40151515151516 %\n",
            "=============================== 10 ===================================\n",
            "The class and their associated probability {3: ('BUTTIGIEG', 0.3531478150440037), 4: ('YANG', 0.3771805701591623), 18: ('BUTTIGIEG', 0.2466362465842136), 41: ('YANG', 0.27568653809971927), 49: ('KLOBUCHAR', 0.29807682443636846), 65: ('WARREN', 0.2251222729501712), 73: ('BIDEN', 0.27735749095601386), 82: ('SANDERS', 0.2601973554041203), 85: ('STEYER', 0.30022759641518004), 88: ('BOOKER', 0.30086865606715363), 102: ('YANG', 0.3348610005066919), 110: ('WARREN', 0.2781012078026645)}\n",
            "Adding row  4  -----  1 / 11\n",
            "Adding row  3  -----  2 / 11\n",
            "Adding row  102  -----  3 / 11\n",
            "Adding row  88  -----  4 / 11\n",
            "Adding row  85  -----  5 / 11\n",
            "Adding row  49  -----  6 / 11\n",
            "Adding row  110  -----  7 / 11\n",
            "Adding row  73  -----  8 / 11\n",
            "Adding row  41  -----  9 / 11\n",
            "Adding row  82  -----  10 / 11\n",
            "Adding row  18  -----  11 / 11\n",
            "Adding row  65  -----  12 / 11\n",
            "The shape of train: (639, 10) \n",
            "test: (0, 8)\n",
            "The shape of train: (639, 432) \n",
            "test: (639, 432)\n",
            "The accuracy of the model after 10  iteration on the update train data is 97.0266040688576 %\n",
            "The accuracy of the model after 10 iteration on the original train data is 96.40151515151516 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUnZpzh2snwm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "a425b509-741e-4bcb-bb6c-d325b3dff66f"
      },
      "source": [
        "print(len(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcKo9adlajdv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "d138ddcf-c29f-492f-c846-17f97b35754f"
      },
      "source": [
        "plt.axes()\n",
        "plt.plot(np.arange(10, 110, 10), accuracy)\n",
        "plt.xlim([0, 120])\n",
        "plt.ylim([0.95, 1])\n",
        "plt.yticks(np.arange(0.95, 1, 0.01))\n",
        "plt.xticks(np.arange(10, 110, 10))\n",
        "\n",
        "plt.title(\"Classification Accuracy vs % test data\")\n",
        "\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel(\"Percentage of test data added to the train set\")\n",
        "plt.ylabel(\"Classification accuracy of original train set\")\n",
        "plt.show()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP-UvXxfvHsI",
        "colab_type": "text"
      },
      "source": [
        "As we keep adding self-labelled test data to the training data and train on this new data, we notice that the accuracy for the original train data which initially now follows a decrease followed by increase pattern. Towards the end, the accuracy of the model for the original train data is a little less than the original regularized logistic regression model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY8J1313S4F7",
        "colab_type": "text"
      },
      "source": [
        "#### 16. Generate labels for semi-supervised\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix1kfzIwvzHB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "9e9a675c-56e7-470c-a42d-e2738ac06b5a"
      },
      "source": [
        "part_3_labels = clf_semi.predict(test_features)\n",
        "print(part_3_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['BUTTIGIEG' 'YANG' 'STEYER' 'BUTTIGIEG' 'YANG' 'BUTTIGIEG' 'WARREN'\n",
            " 'SANDERS' 'GABBARD' 'BUTTIGIEG' 'BOOKER' 'BUTTIGIEG' 'GABBARD'\n",
            " 'BUTTIGIEG' 'KLOBUCHAR' 'WARREN' 'YANG' 'SANDERS' 'BUTTIGIEG' 'HARRIS'\n",
            " 'WARREN' 'BOOKER' 'BUTTIGIEG' 'BIDEN' 'HARRIS' 'SANDERS' 'OROURKE'\n",
            " 'HARRIS' 'BUTTIGIEG' 'HARRIS' 'HARRIS' 'STEYER' 'GABBARD' 'SANDERS'\n",
            " 'WARREN' 'BUTTIGIEG' 'WARREN' 'OROURKE' 'BOOKER' 'WARREN' 'WARREN' 'YANG'\n",
            " 'HARRIS' 'BUTTIGIEG' 'BOOKER' 'HARRIS' 'HARRIS' 'SANDERS' 'WARREN'\n",
            " 'KLOBUCHAR' 'BUTTIGIEG' 'HARRIS' 'KLOBUCHAR' 'HARRIS' 'HARRIS' 'HARRIS'\n",
            " 'KLOBUCHAR' 'SANDERS' 'WARREN' 'WARREN' 'WARREN' 'BUTTIGIEG' 'BUTTIGIEG'\n",
            " 'OROURKE' 'SANDERS' 'WARREN' 'HARRIS' 'OROURKE' 'BUTTIGIEG' 'WARREN'\n",
            " 'HARRIS' 'OROURKE' 'BUTTIGIEG' 'BIDEN' 'SANDERS' 'BUTTIGIEG' 'WARREN'\n",
            " 'SANDERS' 'WARREN' 'BOOKER' 'WARREN' 'YANG' 'SANDERS' 'BIDEN' 'SANDERS'\n",
            " 'STEYER' 'KLOBUCHAR' 'HARRIS' 'BOOKER' 'KLOBUCHAR' 'BUTTIGIEG' 'BIDEN'\n",
            " 'BIDEN' 'WARREN' 'BUTTIGIEG' 'WARREN' 'YANG' 'WARREN' 'WARREN'\n",
            " 'KLOBUCHAR' 'OROURKE' 'WARREN' 'YANG' 'HARRIS' 'WARREN' 'GABBARD' 'YANG'\n",
            " 'SANDERS' 'HARRIS' 'BUTTIGIEG' 'WARREN']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SW5rByvv8ae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1f3c9d10-efc9-4bed-fc90-251ea561c08b"
      },
      "source": [
        "#sanity check\n",
        "print(\"The length of the predicted values \", len(part_3_labels))\n",
        "#extract file name from test_df\n",
        "file_label = test_df.file_name.tolist()\n",
        "print(file_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the predicted values  111\n",
            "['test_78.txt', 'test_64.txt', 'test_96.txt', 'test_94.txt', 'test_3.txt', 'test_28.txt', 'test_36.txt', 'test_39.txt', 'test_69.txt', 'test_65.txt', 'test_90.txt', 'test_102.txt', 'test_32.txt', 'test_22.txt', 'test_44.txt', 'test_87.txt', 'test_19.txt', 'test_88.txt', 'test_13.txt', 'test_41.txt', 'test_93.txt', 'test_16.txt', 'test_42.txt', 'test_63.txt', 'test_97.txt', 'test_35.txt', 'test_6.txt', 'test_98.txt', 'test_79.txt', 'test_101.txt', 'test_82.txt', 'test_48.txt', 'test_55.txt', 'test_84.txt', 'test_46.txt', 'test_33.txt', 'test_38.txt', 'test_51.txt', 'test_17.txt', 'test_14.txt', 'test_75.txt', 'test_34.txt', 'test_111.txt', 'test_95.txt', 'test_20.txt', 'test_4.txt', 'test_57.txt', 'test_68.txt', 'test_29.txt', 'test_91.txt', 'test_43.txt', 'test_73.txt', 'test_109.txt', 'test_50.txt', 'test_86.txt', 'test_26.txt', 'test_47.txt', 'test_11.txt', 'test_25.txt', 'test_103.txt', 'test_76.txt', 'test_56.txt', 'test_105.txt', 'test_54.txt', 'test_62.txt', 'test_108.txt', 'test_52.txt', 'test_12.txt', 'test_9.txt', 'test_24.txt', 'test_27.txt', 'test_92.txt', 'test_7.txt', 'test_23.txt', 'test_67.txt', 'test_21.txt', 'test_2.txt', 'test_37.txt', 'test_72.txt', 'test_31.txt', 'test_77.txt', 'test_1.txt', 'test_18.txt', 'test_61.txt', 'test_49.txt', 'test_89.txt', 'test_80.txt', 'test_104.txt', 'test_71.txt', 'test_59.txt', 'test_66.txt', 'test_110.txt', 'test_99.txt', 'test_81.txt', 'test_30.txt', 'test_83.txt', 'test_8.txt', 'test_70.txt', 'test_85.txt', 'test_5.txt', 'test_106.txt', 'test_40.txt', 'test_10.txt', 'test_60.txt', 'test_100.txt', 'test_53.txt', 'test_45.txt', 'test_58.txt', 'test_15.txt', 'test_74.txt', 'test_107.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCAeTtuOwT5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "fdc4baa1-420f-4ae3-f41d-525945b25bb2"
      },
      "source": [
        "#convert to a dataframe\n",
        "final_submission = pd.DataFrame({'FILE': file_label, 'MODEL1':part_2_labels, 'MODEL2': part_3_labels})\n",
        "final_submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FILE</th>\n",
              "      <th>MODEL1</th>\n",
              "      <th>MODEL2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_78.txt</td>\n",
              "      <td>BUTTIGIEG</td>\n",
              "      <td>BUTTIGIEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_64.txt</td>\n",
              "      <td>YANG</td>\n",
              "      <td>YANG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_96.txt</td>\n",
              "      <td>STEYER</td>\n",
              "      <td>STEYER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_94.txt</td>\n",
              "      <td>BUTTIGIEG</td>\n",
              "      <td>BUTTIGIEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_3.txt</td>\n",
              "      <td>GABBARD</td>\n",
              "      <td>YANG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          FILE     MODEL1     MODEL2\n",
              "0  test_78.txt  BUTTIGIEG  BUTTIGIEG\n",
              "1  test_64.txt       YANG       YANG\n",
              "2  test_96.txt     STEYER     STEYER\n",
              "3  test_94.txt  BUTTIGIEG  BUTTIGIEG\n",
              "4   test_3.txt    GABBARD       YANG"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-z9OYf60Du9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sorting by file name\n",
        "submission_df = final_submission.sort_values('FILE')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW_sD7ux0Ow7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "61ec3f7b-49da-4d38-d57e-aa07909c308e"
      },
      "source": [
        "submission_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FILE</th>\n",
              "      <th>MODEL1</th>\n",
              "      <th>MODEL2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>test_1.txt</td>\n",
              "      <td>BUTTIGIEG</td>\n",
              "      <td>YANG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>test_10.txt</td>\n",
              "      <td>BUTTIGIEG</td>\n",
              "      <td>YANG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>test_100.txt</td>\n",
              "      <td>WARREN</td>\n",
              "      <td>WARREN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>test_101.txt</td>\n",
              "      <td>GABBARD</td>\n",
              "      <td>HARRIS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>test_102.txt</td>\n",
              "      <td>BUTTIGIEG</td>\n",
              "      <td>BUTTIGIEG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             FILE     MODEL1     MODEL2\n",
              "81     test_1.txt  BUTTIGIEG       YANG\n",
              "102   test_10.txt  BUTTIGIEG       YANG\n",
              "104  test_100.txt     WARREN     WARREN\n",
              "29   test_101.txt    GABBARD     HARRIS\n",
              "11   test_102.txt  BUTTIGIEG  BUTTIGIEG"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEuVAcsowyAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CONVERT TO TXT FILE\n",
        "final_submission.to_csv('submission.txt', sep='\\t', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}